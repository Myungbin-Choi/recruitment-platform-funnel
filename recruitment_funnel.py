# -*- coding: utf-8 -*-
"""ì¤‘ê¸‰í”„ë¡œì íŠ¸_3íŒ€_ìµœì¢…ì •ë¦¬_gitìš©.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16pmd3BSN-VHAbS6H2RFDdRsTChera9_f

# 0. í™˜ê²½ì„¤ì • ë° ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
"""

! pip install koreanize_matplotlib

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import koreanize_matplotlib

data_path = '/content/drive/MyDrive/á„á…©á„ƒá…³á„‹á…µá†º_á„ƒá…¦á„‹á…µá„á…¥á„‡á…®á†«á„‰á…¥á†¨_6á„€á…µ/á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/á„Œá…®á†¼á„€á…³á†¸ á„‡á…®á†«á„‰á…¥á†¨ á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/á„Œá…®á„Œá…¦ 1. á„€á…®á†¨á„‚á…¢ á„á…¢á„‹á…­á†¼á„‰á…µá„Œá…¡á†¼ á„†á…µá†¾ á„á…¢á„‹á…­á†¼ á„‘á…³á†¯á„…á…¢á†ºá„‘á…©á†· á„‹á…µá„‹á…­á†¼á„‘á…¢á„á…¥á†« á„‡á…®á†«á„‰á…¥á†¨/log_2023.csv'
log_2023_df = pd.read_csv(data_path, index_col=0)

"""# 1. ë¡œê·¸ ë°ì´í„° ì „ì²˜ë¦¬"""

log_2023_df.shape

log_2023_df.head(3)

"""## ë°ì´í„°íƒ€ì… ë³€ê²½ : date ì»¬ëŸ¼ datetimeìœ¼ë¡œ"""

log_2023_df.info()

log_2023_df['date'] = pd.to_datetime(log_2023_df['date'])

log_2023_df.info()

"""## response code ì „ì²˜ë¦¬"""

log_2023_df['response_code'].value_counts()

"""```python
2xx : ì„±ê³µ
3xx : ë¦¬ë‹¤ì´ë ‰ì…˜, ìš”ì²­ ì™„ë£Œë¥¼ ìœ„í•´ ë¦¬ë‹¤ì´ë ‰ì…˜ì´ ì´ë£¨ì–´ì ¸ì•¼ í•œë‹¤ (ì™¸ë¶€ ì›¹ì„œë²„ë¡œ ì—°ê²°ë˜ëŠ” ë“±)
4xx : í´ë¼ì´ì–¸íŠ¸ ì˜¤ë¥˜
5xx : ì„œë²„ ì˜¤ë¥˜

â†’ ì‚¬ìš©ì ê¸°ë¡ì—ì„œì˜ ì˜¤ë¥˜ë¥¼ ì œê±°í•˜ê¸° ìœ„í•´ì„œ 4xx, 5xxëŠ” ì‚­ì œí•œë‹¤
```
"""

delete_response_code = log_2023_df['response_code'].isin([404, 400, 409, 500, 401, 405, 503, 403])
log_2023_df = log_2023_df[~delete_response_code]

log_2023_df['response_code'].value_counts()

"""## URL ì „ì²˜ë¦¬

### URL nanê°’ ì‚­ì œ : 369,434ê°œ í–‰ ì‚­ì œ
- ë¡œê·¸ ë°ì´í„° ë¶„ì„ì„ ìœ„í•´ì„œëŠ” URL ê°’ì´ í•„ìš”í•˜ê³ , URL ì •ë³´ê°€ ì—†ëŠ” ë¡œê·¸ëŠ” ë°ì´í„° ì˜¤ë¥˜ë¡œ íŒë‹¨í•¨
"""

log_2023_df.dropna(inplace=True)
log_2023_df.isna().sum()

"""```python
URLì— ë³´ì´ëŠ” í‚¤ì›Œë“œ 1ì°¨ ë¶„ë¥˜
- êµ¬ì§ì : /search/, /users/, @user_id, jobs/id/, setting, timeline, recommend, guided action, apply_progress, suggest,
verify, continue?next=/@, help/id, verify_phone, api/job_offer, api/post/id/, remove, api/project/form_data/media,
api/jobs/user_filter/id, user_received, continue?next=/jobs, api/jobs/widget/widget_templates, jobs?specialty=, people?rel=1,
people?keywords=, api/references, api/jobs/collections/template, api/ask-manager/id, jobs?location, api/media/id/form,
api/specialties/id/follow_button, jobs?career_type, api/people/template, /signup/
- ê¸°ì—… : jobs?page=&job, pricing, api/jobs/form_data/media, api/page/id/form
- ê¸°íƒ€ : people, zip_code?index=, api/application_thread_comment/id, app,
password_reset, email_verify\?code=, people\?school, people\?job=1&location=, api/page/id/view, api/page/id/form
```

### admin ì œê±°

<mark> ìš°ë¦¬ì˜ ë¶„ì„ íƒ€ê²Ÿì€ 'ìœ ì €'ì´ë¯€ë¡œ ì œê±° ë¡œê·¸ì— 'admin'ì´ í¬í•¨ëœ ê²ƒì€ ì œì™¸
- api/search/people/job_title?name=ë©¸ì¹˜TV A(melchi App) ë° adminê´€ë¦¬ ì‹œìŠ¤í…œ ë©”ì¸ ê¸°íš ë° ìš´ì˜ ë§¤ë‹ˆì €&_=1699526824841	ì´ëŸ° ë¡œê·¸ëŠ” adminì¼ ìˆ˜ë„ ìˆê³ , ê¸°ì—… ë‹´ë‹¹ìì¼ ìˆ˜ë„ ìˆìœ¼ë‚˜ 'ìœ ì €'ëŠ” ì•„ë‹ˆë¯€ë¡œ ì œê±°
"""

condition_admin = log_2023_df['URL'].str.contains('admin')
log_2023_df.loc[condition_admin, 'URL'].value_counts()

log_2023_df = log_2023_df[~condition_admin]

"""### company ì œê±°

<mark> ìš°ë¦¬ì˜ ë¶„ì„ íƒ€ê²Ÿì€ 'ìœ ì €'ì´ë¯€ë¡œ ëª…ë°±í•˜ê²Œ companyì¸ ê²ƒì€ ì œì™¸í•˜ê³  ì§„í–‰

```python
- pricing : ê²°ì œì™€ ê´€ë ¨ëœ ì„ íƒì€ ëŒ€ë¶€ë¶„ ê¸°ì—…ì—ê²Œ
- api/jobs/form_data/media : ì±„ìš©ê³µê³  ë¯¸ë””ì–´ ìˆ˜ì •
- api/companies/id/ad_stat/progress : ê´‘ê³  ê´€ë ¨
- api/page/id/form : í˜ì´ì§€ ì–‘ì‹ POST methodë¼ ê¸°ì—…
- api/page/id/view : í˜ì´ì§€ ë·° POST methodë¼ ê¸°ì—…
- api/people/template : íŠ¹ì •ì¸ì˜ í…œí”Œë¦¿ ë³´ëŠ” ê²ƒ
- api/users/id/request_button : ìš”ì²­í•˜ê¸° ë²„íŠ¼ > ì£¼ë¡œ ê¸°ì—…ì´ ì–´ë–¤ ì‚¬ëŒì— ëŒ€í•œ ì •ë³´ ì—´ëŒ ìš”ì²­ ì‹œì— ì‚¬ìš©
- jobs/id/applications : ì§ë¬´ ì§€ì›ì ë¦¬ìŠ¤íŠ¸ í˜¸ì¶œ
- api/companies/id/form	: ê¸°ì—…ì˜ ì •ë³´ ì…ë ¥/ìˆ˜ì • í¼ ë¡œë“œ
```
"""

pattern_company = (
    'pricing|api/jobs/form_data/media|api/companies/id/ad_stat/progress|api/page/id/view|api/people/template|'
    'api/page/id/form|api/users/id/request_button|jobs/id/applications.*|api/companies/id/form'
)
condition_companies = log_2023_df['URL'].str.contains(pattern_company, regex=True, na=False)

log_2023_filtering = log_2023_df[~condition_companies]

log_2023_filtering

# ì œê±°ëœ log_2023_filtering ì•ˆì— ì•„ì§ ë‚¨ì•„ìˆëŠ” patternì´ ìˆëŠ”ì§€ í™•ì¸
has_company_pattern = log_2023_filtering['URL'].str.contains(pattern_company).any()

if has_company_pattern:
    print("âš ï¸ log_2023_filteringì— ì—¬ì „íˆ pattern_company ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” URLì´ ë‚¨ì•„ ìˆìŠµë‹ˆë‹¤.")
    # ë‚¨ì•„ìˆëŠ” ê²ƒ í™•ì¸í•´ë³´ê³  ì‹¶ë‹¤ë©´:
    remaining_logs = log_2023_filtering[log_2023_filtering['URL'].str.contains(pattern_company)]
    display(remaining_logs['URL'].unique())
else:
    print("âœ… log_2023_filteringì—ëŠ” pattern_companyì— í•´ë‹¹í•˜ëŠ” URLì´ ì™„ì „íˆ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤.")

"""### 'app' url ì‚­ì œ

<mark> ìš°ë¦¬ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ëª©í‘œëŠ” ì§€ì›ì„œë¥¼ ì™„ë£Œê¹Œì§€ í•˜ê²Œ í•˜ëŠ” ê²ƒì´ ìµœì¢… ëª©í‘œì´ê³ , ì´ê²ƒì€ PCë¡œ ì´ë£¨ì–´ì§€ë¯€ë¡œ app ì ‘ì†ì€ ì œì™¸í•˜ê¸°ë¡œ í•¨
"""

condition_app = log_2023_df['URL'].isin(['app'])
log_2023_df.loc[condition_app, 'URL'].value_counts()

log_2023_filtering = log_2023_df[~condition_app]

log_2023_filtering

# ì œê±° í›„ì—ë„ 'app'ì´ ë‚¨ì•„ìˆëŠ”ì§€ í™•ì¸
has_app = log_2023_filtering['URL'].isin(['app']).any()

if has_app:
    print("âš ï¸ 'app' URLì´ ì•„ì§ log_2023_filteringì— ë‚¨ì•„ ìˆìŠµë‹ˆë‹¤.")
    print(log_2023_filtering[log_2023_filtering['URL'] == 'app'])
else:
    print("âœ… 'app' URLì€ log_2023_filteringì—ì„œ ì™„ì „íˆ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤.")

"""## ë¶„ì„ê¸°ê°„ ì„¤ì • : 2023ë…„ 4ì›”~ 2023ë…„ 9ì›”
- ê¸°ì—…ì˜ ì±„ìš©ê³µê³  ì—…ë¡œë“œê°€ ì•„ì£¼ ë§ê±°ë‚˜(ì—°ì´ˆ) ì ì€ ë‹¬(ì—°ë§)ì€ ê²½í–¥ì„±ì„ íŒŒì•…í•¨ì— ìˆì–´ ì™œê³¡ì„ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, í•´ë‹¹ ê¸°ê°„ì„ ì œì™¸í•œ 6ê°œì›”ì„ ë¶„ì„ê¸°ê°„ìœ¼ë¡œ ì„¤ì •
"""

log_2023_filtering.shape

log_2023_filtering = log_2023_filtering[
    (log_2023_filtering['date'].dt.month >= 4) &
    (log_2023_filtering['date'].dt.month <= 9)
]

log_2023_filtering.shape

"""## 1ì°¨ ë°ì´í„° ì¶”ì¶œ"""

save_path = '/content/drive/MyDrive/á„á…©á„ƒá…³á„‹á…µá†º_á„ƒá…¦á„‹á…µá„á…¥á„‡á…®á†«á„‰á…¥á†¨_6á„€á…µ/á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/ì¤‘ê¸‰ á„‡á…®á†«á„‰á…¥á†¨ á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/'
data_name = 'log_2023_filtering.csv'
data_path = save_path + data_name

log_2023_filtering.to_csv(data_path, index=False)

data_df = pd.read_csv(data_path, index_col=0)

data_df.shape

"""# 2. í¼ë„ ë‹¨ê³„ ë¶„ë¥˜"""

data_path = '/content/drive/MyDrive/á„á…©á„ƒá…³á„‹á…µá†º_á„ƒá…¦á„‹á…µá„á…¥á„‡á…®á†«á„‰á…¥á†¨_6á„€á…µ/á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/á„Œá…®á†¼á„€á…³á†¸ á„‡á…®á†«á„‰á…¥á†¨ á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/log_2023_filtering.csv'
log = pd.read_csv(data_path)

"""## 1ë‹¨ê³„ : ë°©ë¬¸/ì§„ì…

```python
[1ë‹¨ê³„ë¡œ ë¶„ë¥˜ëœ URL]
- setting?utm_source=notification&utm_medium=ema... : ì´ë©”ì¼ í‘¸ì‹œë¥¼ í†µí•´ ì ‘ì†
- api/job_offer/ : ì˜¤í¼ ë°›ëŠ” ë‚´ìš©ì„ í™•ì¸í•˜ê¸° ìœ„í•´ í´ë¦­
- ?user_received : íŠ¹ì •ì‚¬ìš©ì IDê°€ ì´ ë§í¬ë¥¼ ë°›ì•˜ë‹¤ëŠ” ë§ˆì¼€íŒ… íŠ¸ë˜í‚¹ ì •ë³´
- signup : íšŒì›ê°€ì…
- api/recommend_specialty : ì¶”ì²œ ì§ë¬´ ê¸°ë°˜ ë§ì¶¤ ê³µê³  ë³´ì—¬ì£¼ê¸° (íƒìƒ‰ ì½˜í…ì¸  ì¤€ë¹„í•˜ëŠ” ë¡œê·¸)
- api/current_guided_action/id : ìœ ì €ì—ê²Œ ë‹¤ìŒ ì¶”ì²œ í–‰ë™ì„ ë°˜í™˜ (ì´ëŸ° ê±¸ í•´ë³´ì„¸ìš”!)
```
"""

pattern_step1 = 'setting\?utm_source|api/job_offer|user_received|signup|api/recommend_specialty|widget|api/current_guided_action/id'
condition_step1 = log['URL'].str.contains(pattern_step1)
condition_step1.sum()

view_step1 = log.loc[condition_step1, 'URL']

view_step1.value_counts()

"""## 2ë‹¨ê³„ : ê°œì¸ ì´ë ¥ì„œ ì‘ì„±
- íœ´ëŒ€í°, ì´ë©”ì¼ ì¸ì¦ ë“±ë„ í•´ë‹¹ ë‹¨ê³„ì—ì„œ ì§„í–‰

```python
[2ë‹¨ê³„ë¡œ ë¶„ë¥˜ëœ URL]
- setting : êµ¬ì§ìê°€ ìì‹ ì˜ í™˜ê²½ì„¤ì • í˜ì´ì§€ì— ì§ì ‘ ì ‘ì†
- email_verify?code : ì´ë©”ì¼ ì¸ì¦
- api/users/id/specialty, api/users/id/form : ìœ ì €ê°€ ìì‹ ì˜ ì •ë³´ë¥¼ ìˆ˜ì •í•˜ëŠ” ë¡œê·¸
- @user_id/resume/step : ì´ë ¥ì„œë¥¼ ì‘ì„±í•˜ëŠ” ë‹¨ê³„ (ì±„ìš©ê³µê³ ì™€ ë¬´ê´€í•œ ìì‹ ì˜ ì´ë ¥ì„œ)
- api/users/id/career/id : ìì‹ ì˜ ê²½ë ¥ì— ëŒ€í•´ í™•ì¸í•˜ê±°ë‚˜ í¸ì§‘í•˜ëŠ” ë‹¨ê³„
- api/users/id/project : ìœ ì €ê°€ ìì‹ ì˜ í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„±
- api/users/id/resume/step : ìì‹ ì˜ ì´ë ¥ì„œë¥¼ ì‘ì„±í•˜ëŠ” ë‹¨ê³„
- @user_id/resume : ìœ ì €ê°€ ìì‹ ì˜ ì´ë ¥ì„œ ë³´ëŠ” í–‰ë™
- @user_id : ìœ ì €ì˜ í”„ë¡œí•„ í™•ì¸ (ì¼ë°˜ì ìœ¼ë¡œ @user_idëŠ” ìê¸° ê³„ì •ì„ ê°€ë¦¬í‚¤ëŠ” êµ¬ì¡°ë¡œ ì„¤ê³„ë¨)
- api/users/id/ : ìœ ì €ê°€ ìì‹ ì˜ ì´ë ¥ì„œë¥¼ ì‘ì„±,í¸ì§‘,ì¡°íšŒí•˜ëŠ” í™œë™
- api/guided_action/add : ìœ ì €ì˜ í”„ë¡œí•„ì— ì¶”ê°€í•˜ë¼ëŠ” ì•¡ì…˜ ìœ ë„
- api/projects/id/media/add	: í”„ë¡œì íŠ¸ì— ë¯¸ë””ì–´ íŒŒì¼ ë”í•˜ê¸°
- api/users/id/template : êµ¬ì§ìê°€ ìê¸° ì†Œê°œì„œ ì–‘ì‹ ë¶ˆëŸ¬ì˜¤ê¸°
- api/media/id/form : êµ¬ì§ìê°€ ìì‹ ì˜ ì´ë¯¸ì§€ íŒŒì¼ ì—…ë¡œë“œ
- api/project/form_data/media : ìì‹ ì˜ í”„ë¡œì íŠ¸ì— ëŒ€í•œ ë¯¸ë””ì–´ íŒŒì¼ ì—…ë¡œë“œ
- api/verify/education/id : POST methodë¥¼ ì“°ê³  ìˆë‹¤ë©´ êµ¬ì§ìê°€ ìì‹ ì˜ ì •ë³´ë¥¼ ìˆ˜ì •í•´ì„œ ì‚¬ì´íŠ¸ì— ì œì¶œí•˜ê³  ê²€ì¦ë°›ëŠ”ê²ƒ, í¼ë„ë¶„ì„ì—ì„œ ì´ë ¥ì„œ ì‘ì„± ë‹¨ê³„(ì¤‘ê°„êµ¬ê°„)
- verify_phone? : íœ´ëŒ€í° ë²ˆí˜¸ë¥¼ ì¸ì¦í•´ì•¼ í•˜ëŠ” í˜ì´ì§€
```
"""

# 5ë‹¨ê³„ë¡œ ë“¤ì–´ê°€ì•¼í•˜ëŠ”ë° ì¤‘ë³µì´ ë˜ëŠ” ì¡°ê±´ (ì§€ì›ì„œ ì‘ì„± ë‹¨ê³„ì—ì„œ ìì‹ ì˜ ê²½í—˜ì„ ìˆ˜ì •í•˜ëŠ” ê²ƒ)
condition_except_step5 = log['URL'].isin(['api/users/id/experience/form?type=apply'])
condition_except_step5.sum()

pattern_step2 = (
    'email_verify\?code|api/users/id/specialty|api/users/id/form|@user_id/resume/step|api/users/id/career/id|api/users/id/project|'
    'api/users/id/resume/step|@user_id/resume|@user_id|api/users/id|api/guided_action/add|api/projects/id/media/add|api/users/id/template|'
    'api/media/id/form|api/project/form_data/media|api/verify/education/id|verify_phone'
)
condition_step2 = (
    ~condition_step1 & ~condition_except_step5 &
    (log['URL'].str.contains(pattern_step2) | log['URL'].isin(['setting']))
)
condition_step2.sum()

view_step2 = log.loc[condition_step2, 'URL']
view_step2.value_counts()

"""## 3ë‹¨ê³„ : íƒìƒ‰

```python
[3ë‹¨ê³„ë¡œ ë¶„ë¥˜ëœ URL]
- timeline : êµ¬ì§ìì˜ í™ˆ í™”ë©´ì—ì„œ ì œê³µë˜ëŠ” ê°œì¸í™”ëœ ì •ë³´ ëª©ë¡(ì¶”ì²œ ì±„ìš©ê³µê³ , ìµœê·¼ ë³¸ ê´‘ê³ , ìŠ¤í¬ë©í•œ ê´‘ê³  ì´ëŸ° ê²ƒë“¤ì´ ë³´ì—¬ì§€ëŠ” ê²ƒ)
- suggest?q=ìƒë¬¼ : ìë™ì™„ì„± ê¸°ëŠ¥ìœ¼ë¡œ 'ìƒë¬¼'ì´ ì œì•ˆë˜ëŠ” ê²ƒ(êµ¬ì§ì)
- api/jobs/job_title?page=&q= : ì±„ìš©ê³µê³  ì§ë¬´ëª… ë¦¬ìŠ¤íŠ¸ ìš”ì²­ (êµ¬ì§ìê°€ ê´€ì‹¬ ì§ë¬´ ê²€ìƒ‰ ë“±)
- api/jobs/job_title?keywords= : ì±„ìš©ê³µê³  í‚¤ì›Œë“œ ìš”ì²­ (êµ¬ì§ìê°€ ê²€ìƒ‰)
- jobs?specialty=SQL : êµ¬ì§ìê°€ ê¸°ìˆ ì— sqlì„ í•„í„°ë§ í•œ ë¡œê·¸
- api/jobs/collections/template : êµ¬ì§ì ë§ì¶¤í˜•ìœ¼ë¡œ ì§€ì›ê³µê³ ê°€ ë‚˜ì˜¤ëŠ” ë¡œê·¸
- jobs?location=  : êµ¬ì§ìê°€ ì§€ì—­ì„ í•„í„°ë§í•´ë³¸ê²ƒ
- api/specialties/id/follow_button : êµ¬ì§ìê°€ íŠ¹ì • ì „ë¬¸ë¶„ì•¼ íŒ”ë¡œìš°/ì–¸íŒ”ë¡œìš°
- api/jobs/user_filter/id : userì˜ ê´€ì‹¬ í•„í„°ë¥¼ ì €ì¥í•˜ê±°ë‚˜ í˜¸ì¶œí• ë•Œ
- search/companies : ê¸°ì—…ì„ ê²€ìƒ‰
- jobs?page=&job=1&salary=60000000-&location=ì„œìš¸íŠ¹...: êµ¬ì§ìê°€ ì¡°ê±´ì„ ê³„ì† í•„í„°ë§í•˜ë©° íƒìƒ‰í•  ë•Œ
- jobs, job, companiesë§Œ ìˆëŠ” ê²ƒ : ì§ë¬´ë‚˜ íšŒì‚¬ í•„í„°ë§í•´ì„œ ê²€ìƒ‰í•˜ê±°ë‚˜ í´ë¦­(ê³µê³  x)
- help/id : êµ¬ì§ìê°€ ë„ì›€ì„ êµ¬í•˜ëŠ” í˜ì´ì§€
- api/post/id/ : ì»¤ë®¤ë‹ˆí‹° ê¸€ì— ëŒ€í•œ ì¡°íšŒ
- people?school : íŠ¹ì • ì‚¬ëŒì˜ í•™êµ í™•ì¸
- people?job=1&location : íŠ¹ì • ì‚¬ëŒì˜ ì§ë¬´, ì£¼ì†Œ íƒìƒ‰
- api/companies/id/view	: ê¸°ì—…ì˜ í˜ì´ì§€ íƒìƒ‰
- companies/company_id/jobs	: íŠ¹ì • ê¸°ì—…ì˜ ì±„ìš©ê³µê³  íƒìƒ‰
- companies/company_id : íŠ¹ì • íšŒì‚¬ì˜ í”„ë¡œí•„ì„ ì¡°íšŒ
- api/jobs/widget/widget_templates : ì±„ìš©ê³µê³  UIë¥¼ ì–´ë–¤ í˜•íƒœë¡œ ëª¨ì—¬ì¤„ì§€ë¥¼ ìœ„í•œ í…œí”Œë¦¿ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë¡œê·¸
- api/companies/id/member_list?oneline=1&offset=3 : íŠ¹ì • ê¸°ì—…ì˜ ë©¤ë²„ ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ
- @user_id/job_offer/received : ìœ ì €ê°€ ë°›ëŠ” ì œì•ˆ ëª©ë¡ í™•ì¸(ìŠ¤ìŠ¤ë¡œ í™•ì¸í•˜ëŠ” ê²ƒ)
- jobs/job_title : íŠ¹ì • ì§ë¬´ì˜ ê³µê³  ë¦¬ìŠ¤íŠ¸ ë³´ì—¬ì£¼ê¸°
- @user_id/bookmark	: ìœ ì €ì˜ ë¶ë§ˆí¬ (job/id/bookmarkê°€ ì•„ë‹ˆê¸° ë•Œë¬¸ì— ê¸°ì—… ë“±ì— ëŒ€í•œ ë¶ë§ˆí¬ë¡œ íŒë‹¨)
- api/search/specialty?name=re : íŠ¹ì • ì „ë¬¸ë¶„ì•¼ë¥¼ ê²€ìƒ‰í•˜ëŠ” ê²ƒ
- api/companies/id/bookmark	: íŠ¹ì • ê¸°ì—… ë¶ë§ˆí¬
- jobs?job=1 : ì±„ìš©ê³µê³ ì—ì„œ íŠ¹ì • ì¡°ê±´ í•„í„°ë§
- api/comapnies/id/follow_button : íŠ¹ì • íšŒì‚¬ íŒ”ë¡œìš°
- api/search/product : íŠ¹ì • ì œí’ˆì´ë‚˜ ì„œë¹„ìŠ¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê²€ìƒ‰
```
"""

pattern_step3 = (
    'timeline|suggest\?q|api/jobs/job_title|jobs\?specialty|api/jobs/collections/template|'
    'jobs\?location|api/specialties/id/follow_button|user_filter|search/companies|jobs\?page=&job|help/id|api/post/id|'
    'people\?school|people\?job=1&location|api/companies/id/view|companies/company_id/jobs|companies/company_id|widget|'
    'api/companies/id/member_list|@user_id/job_offer/received|jobs/job_title|@user_id/bookmark|'
    'api/search/specialty\?name=re|api/companies/id/bookmark|jobs\?job=|api/comapnies/id/follow_button|api/search/product'
)
condition_step3 = (
    ~condition_step1 & ~condition_step2 &
    (log['URL'].str.contains(pattern_step3) | log['URL'].isin(['jobs', 'people', 'companies', 'job']))
)
condition_step3.sum()

view_step3 = log.loc[condition_step3, 'URL']
view_step3.value_counts()

"""## 4ë‹¨ê³„ : ê³µê³  ì¡°íšŒ (íŠ¹ì • ê³µê³ ë¥¼ í´ë¦­)

```python
[4ë‹¨ê³„ë¡œ ë¶„ë¥˜ëœ URL]
- jobs/id/id_title : ì±„ìš©ê³µê³  í´ë¦­
- people?company : ê·¸ íšŒì‚¬ì˜ 'êµ¬ì„±ì›(people)' ë³´ê¸° í´ë¦­
- people?rel=1 : íŠ¹ì • íšŒì‚¬ì˜ êµ¬ì„±ì› ì •ë³´ í™•ì¸ (ê¸°ì—…ì¼ ê°€ëŠ¥ì„±ë„ ìˆì§€ë§Œ ë‚®ìŒ)
- people?keywords=í¬ë¦¬ë‚™&q=    : í¬ë¦¬ë‚™ì´ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ(ì•„ë§ˆë„ íšŒì‚¬) êµ¬ì„±ì› ì°¾ëŠ” ë¡œê·¸
- api/ask-manager/id : êµ¬ì§ìê°€ ë§¤ë‹ˆì €(ê¸°ì—…ë‹´ë‹¹ì)ì—ê²Œ ì§ˆë¬¸í•˜ê¸°
- api/jobs/id/other_jobs?offset=0&limit=5 : í˜„ì¬ ë³´ê³  ìˆëŠ” ê³µê³ ì™€ ê´€ë ¨ëœ ë‹¤ë¥¸ ê³µê³ ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ìš”ì²­
- api/jobs/id/other_jobs : ê´€ë ¨ ê³µê³  ë¶ˆëŸ¬ì˜¤ê¸°
- jobs/id/bookmark : íŠ¹ì • ê³µê³  ë¶ë§ˆí¬
- api/jobs/id/follow_button	: í•´ë‹¹ ê³µê³  íŒ”ë¡œìš°
```
"""

pattern_step4 = (
    'jobs/id/id_title|people\?company|people\?rel=1|api/ask-manager/id|api/jobs/id/other_jobs\?offset=0&limit=5|api/jobs/id/other_jobs|'
    'jobs/id/bookmark|api/jobs/id/follow_button'
)
condition_step4 = (
    ~condition_step1 & ~condition_step2 & ~condition_step3 & log['URL'].str.contains(pattern_step4)
)
condition_step4.sum()

view_step4 = log.loc[condition_step4, 'URL']
view_step4.value_counts()

"""## 5ë‹¨ê³„ : ì§€ì›ì„œ ì‘ì„±

```python
[5ë‹¨ê³„ë¡œ ë¶„ë¥˜ëœ URL]
- continue?next=/@didwndckd/applications : ë¡œê·¸ì¸ ë¦¬ë””ë™ì…˜
- continue?next=/jobs/132489/apply/step1&token=1...   : ë¡œê·¸ì¸ í›„ ê³µê³  ì§€ì› ì‹œì‘ í˜ì´ì§€ë¡œ ì´ë™í•˜ëŠ” ë¡œê·¸
- api/references : ì§€ì›í•  ë•Œ ì¶”ì²œì¸ê³¼ ê´€ë ¨ëœ ë¡œê·¸
- jobs/id/apply/step : ì§€ì›ì„œ ì‘ì„± ë‹¨ê³„
- api/jobs/id/template_oneclick	: ì¼ì¢…ì˜ 'ê°„í¸ì§€ì›' ë²„íŠ¼
- api/users/id/experience/form?type=apply : ìì‹ ì˜ ê²½ë ¥ì •ë³´ í¼ ë¶ˆëŸ¬ì˜¤ê¸°(ì±„ìš©ê³µê³ ì—ì„œ)
```
"""

# 5ë‹¨ê³„ë¡œ ë“¤ì–´ê°€ì•¼í•˜ëŠ”ë° ì¤‘ë³µì´ ë˜ëŠ” ì¡°ê±´ (ì±„ìš©ê³µê³  ë‹¨ê³„ì—ì„œ ìì‹ ì˜ ê²½í—˜ì„ ìˆ˜ì •í•˜ëŠ” ê²ƒ)
condition_except_step5 = log['URL'].isin(['api/users/id/experience/form?type=apply'])
condition_except_step5.sum()

pattern_step5 = (
    'continue\?next=/@|continue\?next=/jobs/|api/references|jobs/id/apply/step|api/jobs/id/template_oneclick'
)
condition_step5 = (
    ~condition_step1 & ~condition_step2 & ~condition_step3 & ~condition_step4 & (log['URL'].str.contains(pattern_step5) | condition_except_step5)
)
condition_step5.sum()

view_step5 = log.loc[condition_step5, 'URL']
view_step5.value_counts()

"""## 6ë‹¨ê³„ : ì§€ì› ì™„ë£Œ

```python
[6ë‹¨ê³„ë¡œ ë¶„ë¥˜ëœ URL]
- @user_id/applications : êµ¬ì§ìê°€ ì§€ì›í•œ ì´ë ¥ í™•ì¸
- apply_progress : ì§€ì›í•œ ê³µê³ ì˜ ì „í˜• ë‹¨ê³„ í™•ì¸
- api/remove_application/id : ì§€ì›ì„œ ì‚­ì œ
- jobs/id/apply/complete : ì§€ì› ì™„ë£Œ
```
"""

pattern_step6 = '@user_id/applications|apply_progress|api/remove_application/id|jobs/id/apply/complete'
condition_step6 = (
    ~condition_step1 & ~condition_step2 & ~condition_step3 & ~condition_step4 & ~condition_step5 & log['URL'].str.contains(pattern_step6)
)
condition_step6.sum()

view_step6 = log.loc[condition_step6, 'URL']
view_step6.value_counts()

"""# 3. í¼ë„ ë°ì´í„° ì´ˆì•ˆ ìƒì„±

## í¼ë„ ë°ì´í„° ë§Œë“¤ê¸°
"""

#1ë‹¨ê³„
pattern_step1 = 'setting\?utm_source|api/job_offer|user_received|signup|api/recommend_specialty|widget|api/current_guided_action/id'
condition_step1 = log['URL'].str.contains(pattern_step1)
step1 = log[condition_step1]
step1_users = set(step1['user_uuid'])

#2ë‹¨ê³„
condition_except_step5 = log['URL'].isin(['api/users/id/experience/form?type=apply'])
pattern_step2 = (
    'email_verify\?code|api/users/id/specialty|api/users/id/form|@user_id/resume/step|api/users/id/career/id|api/users/id/project|'
    'api/users/id/resume/step|@user_id/resume|@user_id|api/users/id|api/guided_action/add|api/projects/id/media/add|api/users/id/template|'
    'api/media/id/form|api/project/form_data/media|api/verify/education/id|verify_phone'
)
condition_step2 = (
    ~condition_step1 & ~condition_except_step5 &
    (log['URL'].str.contains(pattern_step2) | log['URL'].isin(['setting']))
)
step2 = log[condition_step2 & log['user_uuid'].isin(step1_users)]
step2_users = set(step2['user_uuid'])

#3ë‹¨ê³„
pattern_step3 = (
    'timeline|suggest\?q|api/jobs/job_title|jobs\?specialty|api/jobs/collections/template|'
    'jobs\?location|api/specialties/id/follow_button|user_filter|search/companies|jobs\?page=&job|help/id|api/post/id|'
    'people\?school|people\?job=1&location|api/companies/id/view|companies/company_id/jobs|companies/company_id|widget|'
    'api/companies/id/member_list|@user_id/job_offer/received|jobs/job_title|@user_id/bookmark|'
    'api/search/specialty\?name=re|api/companies/id/bookmark|jobs\?job=|api/comapnies/id/follow_button|api/search/product'
)
condition_step3 = (
    ~condition_step1 & ~condition_step2 &
    (log['URL'].str.contains(pattern_step3) | log['URL'].isin(['jobs', 'people', 'companies', 'job']))
)

step3 = log[condition_step3 & log['user_uuid'].isin(step2_users)]
step3_users = set(step3['user_uuid'])

#4ë‹¨ê³„
pattern_step4 = (
    'jobs/id/id_title|people\?company|people\?rel=1|api/ask-manager/id|api/jobs/id/other_jobs\?offset=0&limit=5|api/jobs/id/other_jobs|'
    'jobs/id/bookmark|api/jobs/id/follow_button'
)
condition_step4 = (
    ~condition_step1 & ~condition_step2 & ~condition_step3 & log['URL'].str.contains(pattern_step4)
)
step4 = log[condition_step4 & log['user_uuid'].isin(step3_users)]
step4_users = set(step4['user_uuid'])

#5ë‹¨ê³„
condition_except_step5 = log['URL'].isin(['api/users/id/experience/form?type=apply'])
pattern_step5 = (
    'continue\?next=/@|continue\?next=/jobs/|api/references|jobs/id/apply/step|api/jobs/id/template_oneclick'
)
condition_step5 = (
    ~condition_step1 & ~condition_step2 & ~condition_step3 & ~condition_step4 & (log['URL'].str.contains(pattern_step5) | condition_except_step5)
)
step5 = log[condition_step5 & log['user_uuid'].isin(step4_users)]
step5_users = set(step5['user_uuid'])

#6ë‹¨ê³„
pattern_step6 = '@user_id/applications|apply_progress|api/remove_application/id|jobs/id/apply/complete'
condition_step6 = (
    ~condition_step1 & ~condition_step2 & ~condition_step3 & ~condition_step4 & ~condition_step5 & log['URL'].str.contains(pattern_step6)
)
step6 = log[condition_step6 & log['user_uuid'].isin(step5_users)]
step6_users = set(step6['user_uuid'])

# ë¡œê·¸ ë‹¨ê³„ ì„¤ëª…í•˜ëŠ” ì»¬ëŸ¼ ì¶”ê°€
step1['step'] = 'step1'
step2['step'] = 'step2'
step3['step'] = 'step3'
step4['step'] = 'step4'
step5['step'] = 'step5'
step6['step'] = 'step6'

# í¼ë„ ë‹¨ê³„ ì „ì²´ ë°ì´í„° í•©ì¹˜ê¸°
funnel_logs = pd.concat([step1, step2, step3, step4, step5, step6], ignore_index=True)

"""## ì „ì²˜ë¦¬"""

# timestamp ë°ì´í„°íƒ€ì… ë³€ê²½
funnel_logs['timestamp'] = pd.to_datetime(funnel_logs['timestamp'].str.replace(" UTC", "", regex=False), errors='coerce')

funnel_logs.info()

"""## ì´ìƒì¹˜ ì œê±°
- í¼ë„ë‹¨ê³„ ì „ì²´ ì´ìš©ê¸°ê°„ì´ 0ë¶„, 6ê°œì›” ì´ìƒì¸ ê°’ ì œê±°
"""

# user_idë³„ë¡œ timestamp ì •ë ¬
funnel_logs = funnel_logs.sort_values(['user_uuid', 'timestamp'])

# ìœ ì €ë³„ë¡œ ë‹¨ê³„ë³„ ì²´ë¥˜ì‹œê°„
# .shift(-1): ë‹¤ìŒ ê°’ì„ í˜„ì¬ ì¤„ì— ë„£ëŠ” pandas ë¬¸ë²•
funnel_logs['next_timestamp'] = funnel_logs.groupby('user_uuid')['timestamp'].shift(-1)

# NaN (ì´íƒˆ ìœ ì €ì˜ ë§ˆì§€ë§‰ ë‹¨ê³„)ì€ í˜„ì¬ timestampë¡œ ì±„ì›Œì„œ time_diff = 0ìœ¼ë¡œ ë§Œë“¤ê¸°
funnel_logs['next_timestamp'] = funnel_logs['next_timestamp'].fillna(funnel_logs['timestamp'])

# ë¶„ ë‹¨ìœ„ë¡œ ê³„ì‚° : dt.total_senconds()ì— 1ë¶„ì€ 60ì´ˆ
funnel_logs['time_diff'] = (funnel_logs['next_timestamp'] - funnel_logs['timestamp']).dt.total_seconds() / 60

# ì¸ë±ìŠ¤ ì •ë¦¬
funnel_logs.reset_index(inplace=True)

# ìœ ì €ë³„ ì „ì²´ ì´ìš©ê¸°ê°„
# ìœ ì €ë³„ ë‹¨ê³„ë³„ ì²´ë¥˜ì‹œê°„(time_diff)ì˜ í•©
user_whole_time = funnel_logs.groupby('user_uuid')['time_diff'].sum().reset_index()
user_whole_time

# ì´ìƒì¹˜ êµ¬í•˜ê¸°
outliers = user_whole_time[
    (user_whole_time['time_diff'] == 0) |
    (user_whole_time['time_diff'] >= 259200)
    ]

# ì´ìƒì¹˜ ê°œìˆ˜ ì¶œë ¥
print(f"ì´ìƒì¹˜ì˜ ê°œìˆ˜: {outliers.shape[0]}ê°œ")

# ì´ìƒì¹˜ì— í•´ë‹¹í•˜ëŠ” user_uuidë¥¼ ì œì™¸í•œ ë°ì´í„°ë§Œ í•„í„°ë§
filtered_user_whole_time = user_whole_time[~user_whole_time['user_uuid'].isin(outliers['user_uuid'])]

# ê²°ê³¼ í™•ì¸
print(f"ì´ìƒì¹˜ê°€ ì œì™¸ëœ ë°ì´í„°ì˜ ê°œìˆ˜: {filtered_user_whole_time.shape[0]}ê°œ")

# filtered_user_whole_timeì— í¬í•¨ëœ user_uuid ëª©ë¡
valid_user_uuids = filtered_user_whole_time['user_uuid']

# funnel_logsì—ì„œ valid_user_uuidsì— í•´ë‹¹í•˜ëŠ” ìœ ì €ë§Œ í•„í„°ë§
filtered_funnel_logs = funnel_logs[funnel_logs['user_uuid'].isin(valid_user_uuids)]

# ê²°ê³¼ í™•ì¸
print(f"í•„í„°ë§ëœ funnel_logsì˜ ë°ì´í„° ê°œìˆ˜: {filtered_funnel_logs.shape[0]}")

print(f"ê¸°ì¡´ funnel_logsì—ì„œ {funnel_logs.shape[0]-filtered_funnel_logs.shape[0]:,}ê°œ user_uuid ì œê±°ë¨")

filtered_funnel_logs.shape

# ë°ì´í„° ì¶”ì¶œ
save_path = '/content/drive/MyDrive/á„á…©á„ƒá…³á„‹á…µá†º_á„ƒá…¦á„‹á…µá„á…¥á„‡á…®á†«á„‰á…¥á†¨_6á„€á…µ/á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/ì¤‘ê¸‰ á„‡á…®á†«á„‰á…¥á†¨ á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/'
data_name = 'filtered_funnel_logs_logs.csv'
data_path = save_path + data_name
filtered_funnel_logs.to_csv(data_path, index=False)

"""# 4. 1ë‹¨ê³„ ì„¸ê·¸ë¨¼íŠ¸ ë¶„ë¥˜ ë° ìµœì¢… í¼ë„ ë°ì´í„° ìƒì„±"""

data_path = '/content/drive/MyDrive/á„á…©á„ƒá…³á„‹á…µá†º_á„ƒá…¦á„‹á…µá„á…¥á„‡á…®á†«á„‰á…¥á†¨_6á„€á…µ/á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/á„Œá…®á†¼á„€á…³á†¸ á„‡á…®á†«á„‰á…¥á†¨ á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/filtered_funnel_logs_logs.csv'
log = pd.read_csv(data_path, index_col=0)

"""## 1ë‹¨ê³„ ì„¸ê·¸ë¨¼íŠ¸ ë¶„ë¥˜"""

# signup ìœ ì €, joboffer ìœ ì €, ë§ˆì¼€íŒ… ê²½ë¡œ ì ‘ì† ìœ ì €, ë‹¨ìˆœ ì ‘ì† ìœ ì €ë¡œ êµ¬ë¶„

pattern_step1_signup = 'signup'
pattern_step1_joboffer = 'api/job_offer'
pattern_step1_marketing = 'setting\?utm_source|user_received'
pattern_step1_etc = 'api/recommend_specialty|widget|api/current_guided_action/id'

condition_signup = log['URL'].str.contains(pattern_step1_signup)
condition_joboffer = log['URL'].str.contains(pattern_step1_joboffer)
condition_marketing = log['URL'].str.contains(pattern_step1_marketing)
condition_etc = log['URL'].str.contains(pattern_step1_etc)

log['step1_segment'] = np.select([condition_signup, condition_joboffer, condition_marketing, condition_etc],
                                 ['signup', 'joboffer', 'marketing', 'etc'], default='none')

log['step1_segment'].value_counts()

# signup ìœ ì €ë§Œ í•„í„°ë§
log_from_signup = log[log['step1_segment'].isin(['signup', 'none'])]
log_from_signup

"""## 1ë‹¨ê³„ signup ìœ ì € ëŒ€ìƒ, ìˆœì„œëŒ€ë¡œ ì´í–‰í•œ ìœ ì € í¼ë„ ë„ì¶œ"""

log_steps = log_from_signup.dropna(subset=['step']).sort_values(['user_uuid', 'timestamp'])
user_step_seq = log_steps.groupby('user_uuid')['step'].apply(list).reset_index()

valid_funnel = ['step1', 'step2', 'step3', 'step4', 'step5', 'step6']

# ìˆœì„œëŒ€ë¡œ ì˜ ê°€ë‹¤ê°€ ì¤‘ê°„ì— ë©ˆì¶˜ ìœ ì € â†’ í¬í•¨ ì˜ˆ) ['step1', 'step2'] â†’ OK
# ìˆœì„œ ê¼¬ì¸ ìœ ì € â†’ ì œì™¸ ì˜ˆ) ['step1', 'step3', 'step2'] â†’ X
# step1ì¡°ì°¨ ì—†ëŠ” ìœ ì € â†’ ì œì™¸

def is_ordered_prefix(seq, valid_funnel):
    index = 0
    for step in seq:
        if index < len(valid_funnel) and step == valid_funnel[index]:
            index += 1
        elif step in valid_funnel[index:]:
            # ì˜¬ë°”ë¥´ì§€ ì•Šì€ ìˆœì„œë¡œ ë‹¤ìŒ step ë“±ì¥ â†’ íƒˆë½
            return False
    return index > 0  # ìµœì†Œ step1ì€ ìˆì–´ì•¼ ìœ íš¨

user_step_seq['valid'] = user_step_seq['step'].apply(lambda x: is_ordered_prefix(x, valid_funnel))

# ì¡°ê±´ì— ë§ëŠ” ìœ ì €ë§Œ í•„í„°
strict_users = set(user_step_seq[user_step_seq['valid']]['user_uuid'])
strict_log = log_from_signup[log_from_signup['user_uuid'].isin(strict_users)]

strict_log.shape

strict_log.head(2)

#1ë‹¨ê³„
pattern_step1 = 'setting\?utm_source|api/job_offer|user_received|signup|api/recommend_specialty|widget|api/current_guided_action/id'
condition_step1 = strict_log['URL'].str.contains(pattern_step1)
step1 = strict_log[condition_step1]
step1_users = set(step1['user_uuid'])

#2ë‹¨ê³„
condition_except_step5 = strict_log['URL'].isin(['api/users/id/experience/form?type=apply'])
pattern_step2 = (
    'email_verify\?code|api/users/id/specialty|api/users/id/form|@user_id/resume/step|api/users/id/career/id|api/users/id/project|'
    'api/users/id/resume/step|@user_id/resume|@user_id|api/users/id|api/guided_action/add|api/projects/id/media/add|api/users/id/template|'
    'api/media/id/form|api/project/form_data/media|api/verify/education/id|verify_phone'
)
condition_step2 = (
    ~condition_step1 & ~condition_except_step5 &
    (strict_log['URL'].str.contains(pattern_step2) | strict_log['URL'].isin(['setting']))
)
step2 = strict_log[condition_step2 & strict_log['user_uuid'].isin(step1_users)]
step2_users = set(step2['user_uuid'])

#3ë‹¨ê³„
pattern_step3 = (
    'timeline|suggest\?q|api/jobs/job_title|jobs\?specialty|api/jobs/collections/template|'
    'jobs\?location|api/specialties/id/follow_button|user_filter|search/companies|jobs\?page=&job|help/id|api/post/id|'
    'people\?school|people\?job=1&location|api/companies/id/view|companies/company_id/jobs|companies/company_id|widget|'
    'api/companies/id/member_list|@user_id/job_offer/received|jobs/job_title|@user_id/bookmark|'
    'api/search/specialty\?name=re|api/companies/id/bookmark|jobs\?job=|api/comapnies/id/follow_button|api/search/product'
)
condition_step3 = (
    ~condition_step1 & ~condition_step2 &
    (strict_log['URL'].str.contains(pattern_step3) | strict_log['URL'].isin(['jobs', 'people', 'companies', 'job']))
)

step3 = strict_log[condition_step3 & strict_log['user_uuid'].isin(step2_users)]
step3_users = set(step3['user_uuid'])

#4ë‹¨ê³„
pattern_step4 = (
    'jobs/id/id_title|people\?company|people\?rel=1|api/ask-manager/id|api/jobs/id/other_jobs\?offset=0&limit=5|api/jobs/id/other_jobs|'
    'jobs/id/bookmark|api/jobs/id/follow_button'
)
condition_step4 = (
    ~condition_step1 & ~condition_step2 & ~condition_step3 & strict_log['URL'].str.contains(pattern_step4)
)
step4 = strict_log[condition_step4 & strict_log['user_uuid'].isin(step3_users)]
step4_users = set(step4['user_uuid'])

#5ë‹¨ê³„
condition_except_step5 = strict_log['URL'].isin(['api/users/id/experience/form?type=apply'])
pattern_step5 = (
    'continue\?next=/@|continue\?next=/jobs/|api/references|jobs/id/apply/step|api/jobs/id/template_oneclick'
)
condition_step5 = (
    ~condition_step1 & ~condition_step2 & ~condition_step3 & ~condition_step4 & (strict_log['URL'].str.contains(pattern_step5) | condition_except_step5)
)
step5 = strict_log[condition_step5 & strict_log['user_uuid'].isin(step4_users)]
step5_users = set(step5['user_uuid'])

#6ë‹¨ê³„
pattern_step6 = '@user_id/applications|apply_progress|api/remove_application/id|jobs/id/apply/complete'
condition_step6 = (
    ~condition_step1 & ~condition_step2 & ~condition_step3 & ~condition_step4 & ~condition_step5 & strict_log['URL'].str.contains(pattern_step6)
)
step6 = strict_log[condition_step6 & strict_log['user_uuid'].isin(step5_users)]
step6_users = set(step6['user_uuid'])

"""# 5. í¼ë„ ë¶„ì„ ê¸°ì´ˆ

## ë‹¨ê³„ë³„ ë¡œê·¸ ìˆ˜
"""

print(f'1ë‹¨ê³„(ë°©ë¬¸,ì§„ì…) ë¡œê·¸ ìˆ˜ : {step1.shape[0]:,}')
print(f'2ë‹¨ê³„(ì´ë ¥ì„œ ì‘ì„±) ë¡œê·¸ ìˆ˜ : {step2.shape[0]:,}')
print(f'3ë‹¨ê³„(íƒìƒ‰) ë¡œê·¸ ìˆ˜ : {step3.shape[0]:,}')
print(f'4ë‹¨ê³„(ê³µê³  ì¡°íšŒ) ë¡œê·¸ ìˆ˜ : {step4.shape[0]:,}')
print(f'5ë‹¨ê³„(ì§€ì›ì„œ ì‘ì„±) ë¡œê·¸ ìˆ˜ : {step5.shape[0]:,}')
print(f'6ë‹¨ê³„(ì§€ì› ì™„ë£Œ) ë¡œê·¸ ìˆ˜ : {step6.shape[0]:,}')

"""## ë‹¨ê³„ë³„ ê³ ìœ  ìœ ì € ìˆ˜"""

print(f'1ë‹¨ê³„ ìœ ì € ìˆ˜ : {len(step1_users):,}')
print(f'2ë‹¨ê³„ ìœ ì € ìˆ˜ : {len(step2_users):,}')
print(f'3ë‹¨ê³„ ìœ ì € ìˆ˜ : {len(step3_users):,}')
print(f'4ë‹¨ê³„ ìœ ì € ìˆ˜ : {len(step4_users):,}')
print(f'5ë‹¨ê³„ ìœ ì € ìˆ˜ : {len(step5_users):,}')
print(f'6ë‹¨ê³„ ìœ ì € ìˆ˜ : {len(step6_users):,}')

"""## ë‹¨ê³„ë³„ ì „í™˜ìœ¨, ì´íƒˆë¥ """

# ë‹¨ê³„ë³„ ì‚¬ìš©ì ìˆ˜ ë¦¬ìŠ¤íŠ¸ë¡œ ì •ë¦¬
step_user_sets = [step1_users, step2_users, step3_users, step4_users, step5_users, step6_users]
step_user_counts = [len(users) for users in step_user_sets]

for i in range(1, len(step_user_counts)):
    prev = step_user_counts[i - 1]
    curr = step_user_counts[i]

    # ì „í™˜ìœ¨
    conversion_rate = (curr / prev * 100) if prev else 0

    # ì´íƒˆë¥ 
    dropoff_rate = ((prev - curr) / prev * 100) if prev else 0

    print(f"{i} â†’ {i+1}ë‹¨ê³„ ì „í™˜ìœ¨: {conversion_rate:.2f}%, ì´íƒˆë¥ : {dropoff_rate:.2f}%")

# ë°ì´í„° ì¶”ì¶œ
save_path = '/content/drive/MyDrive/á„á…©á„ƒá…³á„‹á…µá†º_á„ƒá…¦á„‹á…µá„á…¥á„‡á…®á†«á„‰á…¥á†¨_6á„€á…µ/á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/ì¤‘ê¸‰ á„‡á…®á†«á„‰á…¥á†¨ á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/'
data_name = 'log_signup_filtering.csv'
data_path = save_path + data_name
strict_log.to_csv(data_path, index=False)

"""# 6. í¼ë„ ë‹¨ê³„ë³„ í˜„í™© ë¶„ì„"""

data_path = '/content/drive/MyDrive/á„á…©á„ƒá…³á„‹á…µá†º_á„ƒá…¦á„‹á…µá„á…¥á„‡á…®á†«á„‰á…¥á†¨_6á„€á…µ/á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/á„Œá…®á†¼á„€á…³á†¸ á„‡á…®á†«á„‰á…¥á†¨ á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/strict_log.csv'
log = pd.read_csv(data_path)

"""## í¼ë„ 2ë‹¨ê³„ ê´€ë ¨

### ê°€ì„¤ 1) ìì‹ ì˜ ì´ë ¥ì„œì— ëŒ€í•œ í™•ì¸ ë° ìˆ˜ì •ì´ ì¦ì€ ìœ ì €ì˜ ê²½ìš°, ì´íƒˆë¥ ì´ ë‚®ì„ ê²ƒì´ë‹¤
- 2ë‹¨ê³„ ë¡œê·¸ê°€ ë§ì´ ì°íŒ ìœ ì €ì¼ ìˆ˜ë¡ ì´íƒˆë¥ ì´ ë‚®ì„ ê²ƒì´ë‹¤
"""

# 2ë‹¨ê³„ ë¡œê·¸ ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìœ ì €ë¥¼ ê·¸ë£¹í™”
step2_segment = step2.groupby('user_uuid')['step'].count().reset_index()
step2_segment.columns = ['user_uuid', 'step2_count']
step2_segment.describe()

# Step2 ë¡œê·¸ ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í™”
# qcut : 4ë¶„ìœ„ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ êµ¬ë¶„
step2_segment['segment'] = pd.qcut(step2_segment['step2_count'], q=3, labels=['low', 'mid', 'high'])

# ê³ ìœ ìœ ì €ê°€ ë„ë‹¬í•œ ìµœëŒ€ ë‹¨ê³„ ê³„ì‚°
user_max_step = log.groupby('user_uuid')['step'].max().reset_index()
user_max_step.columns = ['user_uuid', 'max_step']
user_max_step['max_step'].value_counts()

user_max_step['max_step'].value_counts()

# ì„¸ê·¸ë¨¼íŠ¸ì™€ ì´íƒˆ ì—¬ë¶€ í•©ì¹˜ê¸°
merged = pd.merge(step2_segment, user_max_step, on='user_uuid', how='inner')

# ì„¸ê·¸ë¨¼íŠ¸ë³„ë¡œ max_step ë¶„í¬ ë³´ê¸°
merged['segment'].value_counts()

# ì„¸ê·¸ë¨¼íŠ¸ë³„ë¡œ ìµœì¢… ë„ë‹¬ ë‹¨ê³„ ë¹„ìœ¨ ë¹„êµ
# pd.crosstab() : ë‘ ê°œì˜ ì»¬ëŸ¼ì„ ê¸°ì¤€ìœ¼ë¡œ ë¹ˆë„í‘œ(êµì°¨í‘œ)ë¥¼ ë§Œë“¤ì–´ì£¼ëŠ” í•¨ìˆ˜, pd.crosstab(row, column)
# normalize='index' : ê° í–‰ ê¸°ì¤€ìœ¼ë¡œ ë¹„ìœ¨(%)ë¡œ ë°”ê¾¸ëŠ” ê²ƒ

pivot = pd.crosstab(merged['segment'], merged['max_step'], normalize='index')
pivot

# ì‹œê°í™”
pivot.plot(kind='bar', stacked=True, figsize=(10, 5), colormap='viridis')

plt.title('ì„¸ê·¸ë¨¼íŠ¸ë³„ ìµœì¢… ë„ë‹¬ ë‹¨ê³„ ë¹„ìœ¨')
plt.xlabel('Step2 ë¡œê·¸ ìˆ˜ ê¸°ì¤€ ì„¸ê·¸ë¨¼íŠ¸')
plt.ylabel('ë‹¨ê³„ë³„ ë„ë‹¬ ë¹„ìœ¨')
plt.legend(title='ìµœì¢… ë„ë‹¬ ë‹¨ê³„', bbox_to_anchor=(1.05, 1), loc='upper left')  # ë²”ë¡€ ì •ë ¬
plt.tight_layout()
plt.show()

"""```python
ğŸ’¡ ì„¸ê·¸ë¨¼íŠ¸ê°€ ë†’ì•„ì§ˆìˆ˜ë¡ ì´íƒˆë¥ ì´ ë‚®ê³ , ìµœì¢… ë‹¨ê³„ ë„ë‹¬ë¥ ì´ ë†’ë‹¤
ğŸ’¡ íŠ¹íˆ, low ê·¸ë£¹ì€ step3~step4 ë‹¨ê³„ì—ì„œ ëŒ€ë¶€ë¶„ ì´íƒˆí•˜ê³ , high ê·¸ë£¹ì€ step6ê¹Œì§€ ê°€ëŠ” ë¹„ìœ¨ì´ 95%
ğŸ’¡ ìì‹ ì˜ ì´ë ¥ì„œì— ëŒ€í•œ í™”ì¸, ìˆ˜ì • ë¹ˆë„ê°€ ë†’ì„ ìœ ì €ì¼ ìˆ˜ë¡ ìµœì¢… ë‹¨ê³„ì— ë„ë‹¬í•˜ëŠ” ë¹„ìœ¨ì´ ë†’ë‹¤
```

### ê°€ì„¤ 2) ê°œì¸ ì´ë ¥ì„œì— ëŒ€í•œ ì§ì ‘ì ì¸ ì…ë ¥/ìˆ˜ì • ë¡œê·¸ê°€ ë§ì„ìˆ˜ë¡ ìµœì¢… ë‹¨ê³„ì— ë„ë‹¬í•  í™•ë¥ ì´ ë†’ë‹¤
- ê°€ì„¤1ê³¼ ë‹¬ë¦¬ ì´ë ¥ì„œì— ëŒ€í•œ ì§ì ‘ì ì¸ ê¸°ì¬, ìˆ˜ì • ë¡œê·¸ê°€ ìˆì–´ì•¼í•¨
"""

# ì´ë ¥ì„œ/í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë ¨ ë¡œê·¸ ìˆ˜ í™•ì¸
resume_logs = strict_log[strict_log["URL"].str.contains("resume|portfolio", na=False)]
print("ì´ë ¥ì„œ/í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë ¨ ì „ì²´ ë¡œê·¸ ìˆ˜:", len(resume_logs))

# step4(ê³µê³  í´ë¦­) & step6(ì§€ì› ì™„ë£Œ) ë¡œê·¸ ì¶”ì¶œ
click_logs = strict_log[strict_log["step"] == "step4"].copy()
apply_logs = strict_log[strict_log["step"] == "step6"].copy()

# ìœ ì €ë³„ ìµœì´ˆ í´ë¦­ & ì§€ì› ì‹œê°„ ê³„ì‚°
click_time_df = click_logs.groupby("user_uuid")["timestamp"].min().reset_index()
click_time_df.rename(columns={"timestamp": "click_time"}, inplace=True)

apply_time_df = apply_logs.groupby("user_uuid")["timestamp"].min().reset_index()
apply_time_df.rename(columns={"timestamp": "apply_time"}, inplace=True)

# ë³‘í•© í›„ ì‹œê°„ì°¨ ê³„ì‚°
click_to_apply_df = pd.merge(click_time_df, apply_time_df, on="user_uuid", how="inner")
click_to_apply_df["click_time"] = pd.to_datetime(click_to_apply_df["click_time"], errors="coerce")
click_to_apply_df["apply_time"] = pd.to_datetime(click_to_apply_df["apply_time"], errors="coerce")
click_to_apply_df["click_to_apply_time"] = (
    (click_to_apply_df["apply_time"] - click_to_apply_df["click_time"]).dt.total_seconds() / 60
)

# â‘  ì „ì²´ ì²´ë¥˜ ì‹œê°„ ê³„ì‚°
explore_time = (
    strict_log.groupby("user_uuid")["time_diff"]
    .sum().reset_index().rename(columns={"time_diff": "explore_time_total"})
)
# â‘¡ step6 ë„ë‹¬ ì—¬ë¶€
step6_users = strict_log[strict_log["step"] == "step6"]["user_uuid"].unique()
explore_time["step6_ë„ë‹¬"] = explore_time["user_uuid"].isin(step6_users).astype(int)

# â‘¢ ìµœì¢… ë„ë‹¬ í¼ë„ ë‹¨ê³„
final_step = (
    strict_log.sort_values(["user_uuid", "timestamp"])
    .groupby("user_uuid")["step"].last().reset_index().rename(columns={"step": "final_step"})
)

# â‘£ ì´ë ¥ì„œ/í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ì • íšŸìˆ˜
resume_edit_count = (
    strict_log[strict_log["URL"].str.contains("resume|portfolio", na=False)]
    .groupby("user_uuid").size().reset_index(name="resume_edit_count")
)

# â‘¤ ìœ ì € ê¸°ë°˜ ë§ˆìŠ¤í„° í…Œì´ë¸” ë³‘í•©
user_step_df = (
    explore_time
    .merge(final_step, on="user_uuid", how="left")
    .merge(resume_edit_count, on="user_uuid", how="left")
    .merge(click_to_apply_df[["user_uuid", "click_to_apply_time"]], on="user_uuid", how="left")
)

# â‘¥ ê²°ì¸¡ê°’ ì²˜ë¦¬
user_step_df["resume_edit_count"] = user_step_df["resume_edit_count"].fillna(0).astype(int)

# 1. ì´ë ¥ì„œ ê´€ë ¨ ë¡œê·¸ (resume ê´€ë ¨ URL í¬í•¨)
resume_keywords = ['resume', 'career', 'project', 'template', 'experience']
resume_logs = strict_log[strict_log['URL'].str.contains('|'.join(resume_keywords), na=False)]

resume_edit_count = resume_logs.groupby('user_uuid').size().reset_index(name='resume_edit_count')

# 2. íƒìƒ‰ ë‹¨ê³„ ì´ ì²´ë¥˜ì‹œê°„ (step3ì—ì„œë§Œ)
explore_logs = strict_log[strict_log['step'] == 'step3']
explore_time_total = explore_logs.groupby('user_uuid')['time_diff'].sum().reset_index(name='explore_time_total')

# 3. í´ë¦­ í›„ ì§€ì›ê¹Œì§€ ê±¸ë¦° ì‹œê°„
click_to_apply_df.columns = ['user_uuid', 'click_to_apply_time', 'click_time', 'apply_time']

# 4. ìœ ì €ë³„ ìµœì¢… ë„ë‹¬ í¼ë„ ë‹¨ê³„
final_step = strict_log.groupby('user_uuid')['step'].last().reset_index(name='final_step')

# 5. ë³‘í•©í•˜ì—¬ user_step_df ìƒì„±
from functools import reduce

dfs_to_merge = [resume_edit_count, explore_time_total, click_to_apply_df, final_step]
user_step_df = reduce(lambda left, right: pd.merge(left, right, on='user_uuid', how='outer'), dfs_to_merge)

# í™•ì¸
display(user_step_df.head())

# âœ… step6 ë„ë‹¬ ì—¬ë¶€ ë¶€ì—¬
step6_users = strict_log[strict_log["step"] == "step6"]["user_uuid"].unique()
user_step_df["step6_ë„ë‹¬"] = user_step_df["user_uuid"].isin(step6_users).astype(int)

# ì´ë ¥ì„œ ë¡œê·¸ê°€ ìˆëŠ” user_uuid ìˆ˜
resume_user_set = set(resume_logs["user_uuid"].unique())
print("ì´ë ¥ì„œ ê´€ë ¨ ë¡œê·¸ë¥¼ ê°€ì§„ ê³ ìœ  ìœ ì € ìˆ˜:", len(resume_user_set))

# user_step_dfì— í¬í•¨ëœ ìœ ì € ì¤‘ ì–¼ë§ˆë‚˜ resume ë¡œê·¸ë¥¼ ê°–ê³  ìˆëŠ”ê°€?
step_user_set = set(user_step_df["user_uuid"].unique())
print("user_step_dfì— í¬í•¨ëœ ìœ ì € ìˆ˜:", len(step_user_set))

# êµì§‘í•©
print("ì´ë ¥ì„œ ë¡œê·¸ + ë¶„ì„ ëŒ€ìƒ ìœ ì € êµì§‘í•© ìˆ˜:", len(resume_user_set & step_user_set))

from scipy.stats import chi2_contingency

# â‘  ì´ë ¥ì„œ ìˆ˜ì • íšŸìˆ˜ êµ¬ê°„ ë¶„ë¥˜
# bins = [0, 1, 3, 5, float("inf")]
bins = [5, 10, 20, 30, float("inf")]
labels = ["0íšŒ", "1~2íšŒ", "3~4íšŒ", "5íšŒ ì´ìƒ"]
user_step_df["resume_group"] = pd.cut(user_step_df["resume_edit_count"], bins=bins, labels=labels, right=False)

# â‘¡ groupbyë¡œ ì „í™˜ìœ¨ ê³„ì‚°
group_summary = (
    user_step_df.groupby("resume_group")["step6_ë„ë‹¬"]
    .agg(["count", "sum"])
    .rename(columns={"sum": "ë„ë‹¬ì ìˆ˜"})
)
group_summary["ì „í™˜ìœ¨(%)"] = (group_summary["ë„ë‹¬ì ìˆ˜"] / group_summary["count"] * 100).round(2)
print(group_summary)

# â‘¢ êµì°¨í‘œ ìƒì„±
contingency_table = pd.crosstab(user_step_df["resume_group"], user_step_df["step6_ë„ë‹¬"])
print("\nğŸ“Š ì´ë ¥ì„œ ìˆ˜ì • íšŸìˆ˜ ê·¸ë£¹ vs Step6 ë„ë‹¬ ì—¬ë¶€ êµì°¨í‘œ:")
print(contingency_table)

# â‘£ ì¹´ì´ì œê³± ê²€ì •
chi2, p, dof, expected = chi2_contingency(contingency_table)
print(f"\nâœ… ì¹´ì´ì œê³± í†µê³„ëŸ‰: {chi2:.2f}")
print(f"ğŸ“ ììœ ë„: {dof}")
print(f"ğŸ“Œ ìœ ì˜í™•ë¥ (p-value): {p:.5f}")

# â‘¤ ì‹œê°í™”
plt.figure(figsize=(8, 6))
plt.bar(group_summary.index, group_summary["ì „í™˜ìœ¨(%)"])
plt.title("ì´ë ¥ì„œ ìˆ˜ì • íšŸìˆ˜ ê·¸ë£¹ë³„ Step6 ë„ë‹¬ë¥ ")
plt.ylabel("ì „í™˜ìœ¨ (%)")
plt.ylim(0, 100)
plt.xlabel("ì´ë ¥ì„œ ìˆ˜ì • íšŸìˆ˜ êµ¬ê°„")
plt.show()

# ğŸ¯ ì´ë ¥ì„œ ìˆ˜ì • ë¡œê·¸ ë³´ìœ  ìœ ì €ë§Œ ì¶”ì¶œ
resume_users = user_step_df[user_step_df["user_uuid"].isin(resume_user_set)].copy()

# ğŸ§  ì´ë ¥ì„œ ìˆ˜ì • íšŸìˆ˜ ê¸°ì¤€ ê·¸ë£¹í™”
def categorize_resume_count(x):
    if x == 0:
        return "0íšŒ"
    elif x <= 2:
        return "1~2íšŒ"
    elif x <= 4:
        return "3~4íšŒ"
    else:
        return "5íšŒ ì´ìƒ"

resume_users["resume_group"] = resume_users["resume_edit_count"].fillna(0).apply(categorize_resume_count)

# ğŸ“Š ê·¸ë£¹ë³„ ë„ë‹¬ë¥  ìš”ì•½
resume_summary = (
    resume_users.groupby("resume_group")["step6_ë„ë‹¬"]
    .agg(["count", "sum"])
    .rename(columns={"sum": "ë„ë‹¬ì ìˆ˜"})
)
resume_summary["ì „í™˜ìœ¨(%)"] = (resume_summary["ë„ë‹¬ì ìˆ˜"] / resume_summary["count"] * 100).round(2)

# ğŸ“ˆ ì¹´ì´ì œê³± ê²€ì •
contingency_table = pd.crosstab(resume_users["resume_group"], resume_users["step6_ë„ë‹¬"])
chi2, p, dof, expected = chi2_contingency(contingency_table)

# í‘œ ì¶œë ¥
display(resume_summary)

# êµì°¨í‘œ ì¶œë ¥
print("ğŸ“Š ì´ë ¥ì„œ ìˆ˜ì • íšŸìˆ˜ ê·¸ë£¹ vs Step6 ë„ë‹¬ ì—¬ë¶€ êµì°¨í‘œ:")
print(contingency_table)

# ê²€ì • ê²°ê³¼
print(f"\nâœ… ì¹´ì´ì œê³± í†µê³„ëŸ‰: {chi2:.2f}")
print(f"ğŸ“ ììœ ë„: {dof}")
print(f"ğŸ“Œ ìœ ì˜í™•ë¥ (p-value): {p:.5f}")

"""## í¼ë„ 3ë‹¨ê³„ ê´€ë ¨

### ê°€ì„¤) 3ë‹¨ê³„ ì²´ë¥˜ì‹œê°„(íƒìƒ‰ì‹œê°„)ì´ ì§§ì„ìˆ˜ë¡ ë‹¤ìŒë‹¨ê³„ë¡œì˜ ì „í™˜ì´ ë‚®ë‹¤
"""

# ì´íƒˆìid ë°ì´í„°
droupoff_3 = step3_users - step4_users
len(droupoff_3)

# ì´íƒˆìë§Œ ìˆëŠ” ë°ì´í„°
log_dropoff_3 = step3[step3['user_uuid'].isin(droupoff_3)]
# ì´íƒˆì í…Œì´ë¸” ì‹œê°„ìˆœìœ¼ë¡œ ì¬ì •ë ¬
log_dropoff_3 = log_dropoff_3.sort_values('timestamp',ascending=True)

step3_dropoff_users = step3_users - step4_users
step3_survivor_users = step3_users & step4_users

step3_user_time = log[log['step']=='step3'].groupby('user_uuid')['time_diff'].mean().reset_index(name='avg_time_diff')

step3_user_time['group'] = step3_user_time['user_uuid'].apply(
    lambda x: 'dropoff' if x in step3_dropoff_users else(
        'survivor' if x in step3_survivor_users else 'other'
    )
)

log_dropoff.dtypes

log_dropoff['timestamp'] = pd.to_datetime(log_dropoff['timestamp'].str.replace(" UTC", "", regex=False), errors='coerce')
log_dropoff['next_timestamp'] = pd.to_datetime(log_dropoff['next_timestamp'].str.replace(" UTC", "", regex=False), errors='coerce')

log_dropoff.dtypes

log_dropoff_3['timestamp'] = pd.to_datetime(
    log_dropoff_3['timestamp'].str.replace(" UTC", "", regex=False),
    errors='coerce'
)

# í˜ì´ì§€ ì²´ë¥˜ì‹œê°„
log_dropoff = log_dropoff_3.sort_values(['user_uuid','timestamp'])
log_dropoff['next_timestamp'] = log_dropoff.groupby('user_uuid')['timestamp'].shift(-1)
log_dropoff['stay_duration'] = (log_dropoff['next_timestamp'] - log_dropoff['timestamp']).dt.total_seconds()

# ê·¹ë‹¨ì ìœ¼ë¡œ ê¸´ê°’ë“¤ ì œê±°í›„ ê´€ì¸¡
q25 = step3_user_time['avg_time_diff'].quantile(0.25)
filtered_step3 = step3_user_time[step3_user_time['avg_time_diff'] <= q25]

filtered_step3

plt.figure(figsize=(13, 5))
sns.histplot(data=filtered_step3, x='avg_time_diff', hue='group', bins=30, kde=True, stat='density', common_norm=False)
plt.title('Step3 â€“ Avg Page Time per User (Outliers Removed)')
plt.xlabel('Avg Time Diff')
plt.ylabel('Density')
plt.show()

# ì´ìƒì¹˜ë¥¼ ì œê±°í•˜ì§€ì•Šì€ ë°ì´í„°(ì „ì²´ step3 ë°ì´í„°)ì—ì„œ ì „í™˜ìì™€ ì´íƒˆìê°„ì˜ ì²´ë¥˜ì‹œê°„ì°¨ì´
# ë¹„ëª¨ìˆ˜ ê²€ì •
# ê°€ì„¤: ì´íƒˆìì˜ ì²´ë¥˜ì‹œê°„ì´ ì „í™˜ìì˜ ì²´ë¥˜ì‹œê°„ë³´ë‹¤ ìœ ì˜ë¯¸í•˜ê²Œ ì§§ë‹¤

from scipy.stats import mannwhitneyu

# dropoff / survivor ê·¸ë£¹ ë°ì´í„° ì¶”ì¶œ
dropoff = step3_user_time[step3_user_time['group'] == 'dropoff']['avg_time_diff']
survivor = step3_user_time[step3_user_time['group'] == 'survivor']['avg_time_diff']

# Mann-Whitney U ê²€ì • ì‹¤í–‰
stat, p_value = mannwhitneyu(dropoff, survivor, alternative='less')

# ê²°ê³¼ ì¶œë ¥
print(f"Mann-Whitney U í†µê³„ëŸ‰: {stat:.4f}")
print(f"p-value: {p_value:.4f}")

if p_value < 0.05:
    print("â†’ ì´íƒˆìì˜ ì²´ë¥˜ì‹œê°„ì´ ì „í™˜ìì˜ ì²´ë¥˜ì‹œê°„ë³´ë‹¤ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•˜ê²Œ ì§§ìŠµë‹ˆë‹¤.")
else:
    print("â†’ ì´íƒˆìì˜ ì²´ë¥˜ì‹œê°„ì´ ì „í™˜ìì˜ ì²´ë¥˜ì‹œê°„ë³´ë‹¤ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•˜ê²Œ ì§§ì§€ ì•ŠìŠµë‹ˆë‹¤")

"""## í¼ë„ 4ë‹¨ê³„ ê´€ë ¨

### ê°€ì„¤1) 4ë‹¨ê³„ ì²´ë¥˜ì‹œê°„(íƒìƒ‰ì‹œê°„)ì´ ì§§ì„ìˆ˜ë¡ ë‹¤ìŒë‹¨ê³„ë¡œì˜ ì „í™˜ì´ ë‚®ë‹¤
"""

# ì´íƒˆë¥ ì´ ê°€ì¥ í° 4 -> 5 ë‹¨ê³„ì—ì„œ
# ê³µê³ í´ë¦­ìˆ˜ì™€ ë‹¤ìŒë‹¨ê³„ì „í™˜ìœ¨ ë¹„êµ
step4_job_click = log[(log['URL'].str.contains('jobs/id/id_title', na=False)) & (log['step'] == 'step4')]
click_counts = step4_job_click.groupby('user_uuid').size().reset_index(name='job_click_counts')

step4_users = set(log[log['step'] =='step4']['user_uuid'])
step5_users = set(log[log['step'] == 'step5']['user_uuid'])
dropoff_users = step4_users - step5_users

click_counts['is_dropoff'] = click_counts['user_uuid'].apply(lambda x: 'dropoff' if x in dropoff_users else 'survivor')

# í‰ê·  ë¹„êµ
print(click_counts.groupby('is_dropoff')['job_click_counts'].describe())

# í´ë¦­ë¥  ê·¸ë˜í”„
plt.figure(figsize=(13, 5))
sns.histplot(data=click_counts, x='job_click_counts', hue='is_dropoff',
             bins=30, kde=True, stat='density', common_norm=False)
plt.title('Step4 â€“ Click Counts')
plt.xlabel('Click counts')
plt.ylabel('Density')
plt.show()

# ì´ìƒì¹˜ë¥¼ ì œê±°í•˜ì§€ì•Šì€ ë°ì´í„°(ì „ì²´ step4 ë°ì´í„°)ì—ì„œ ì „í™˜ìì™€ ì´íƒˆìê°„ì˜ í´ë¦­ìˆ˜ì°¨ì´
# ë¹„ëª¨ìˆ˜ ê²€ì •

# ê°€ì„¤: ì´íƒˆìì˜ í´ë¦­ ìˆ˜ê°€ ì „í™˜ìì˜ í´ë¦­ ìˆ˜ë³´ë‹¤ ìœ ì˜ë¯¸í•˜ê²Œ ì ë‹¤

# dropoff / survivor ê·¸ë£¹ ë°ì´í„° ì¶”ì¶œ
dropoff = click_counts[click_counts['is_dropoff'] == 'dropoff']['job_click_counts']
survivor = click_counts[click_counts['is_dropoff'] == 'survivor']['job_click_counts']

# Mann-Whitney U ê²€ì • ì‹¤í–‰
stat, p_value = mannwhitneyu(dropoff, survivor, alternative='less')

# ê²°ê³¼ ì¶œë ¥
print(f"Mann-Whitney U í†µê³„ëŸ‰: {stat:.4f}")
print(f"p-value: {p_value:.4f}")

if p_value < 0.05:
    print("â†’ ì´íƒˆìì˜ í´ë¦­ ìˆ˜ê°€ ì „í™˜ìì˜ í´ë¦­ ìˆ˜ë³´ë‹¤ ìœ ì˜ë¯¸í•˜ê²Œ ì ë‹¤")
else:
    print("â†’ ì´íƒˆìì˜ í´ë¦­ ìˆ˜ê°€ ì „í™˜ìì˜ í´ë¦­ ìˆ˜ë³´ë‹¤ ìœ ì˜ë¯¸í•˜ê²Œ ì ì§€ ì•Šë‹¤")

"""### ê°€ì„¤2) ì§€ì› ê³µê³ ì— ëŒ€í•œ í´ë¦­ì´ ì¦ì€ ìœ ì €ì˜ ê²½ìš°, ì´íƒˆë¥ ì´ ë‚®ì„ ê²ƒì´ë‹¤"""

# ì§€ì› ê³µê³ ì— ëŒ€í•œ í´ë¦­ URLì„ ê°€ì§„ ë¡œê·¸ë§Œ í•„í„°ë§
jobclick_condition = step4['URL'].str.contains('jobs/id/id_title')
step4_jobclick = step4[(jobclick_condition)]

# ë¡œê·¸ ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í™”
step4_jobclick_segment = step4_jobclick.groupby('user_uuid')['step'].count().reset_index()
step4_jobclick_segment.columns = ['user_uuid', 'step4_count']
step4_jobclick_segment

# ì§€ì›ê³µê³  í´ë¦­ ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì„¸ê·¸ë¨¼íŠ¸ ë¶„ë¥˜
step4_jobclick_segment['segment'] = pd.qcut(step4_jobclick_segment['step4_count'], q=3, labels=['low', 'mid', 'high'])
step4_jobclick_segment.head(2)

# ê¸°ì¡´ ìµœê³  ë‹¨ê³„ ë°ì´í„°ì™€ í•©ì¹˜ê¸°
merged = pd.merge(step4_jobclick_segment, user_max_step, on='user_uuid', how='inner')
merged['segment'].value_counts()

# ì„¸ê·¸ë¨¼íŠ¸ë³„ ìµœì¢… ë„ë‹¬ ë‹¨ê³„ ë¹„êµ
pivot = pd.crosstab(merged['segment'], merged['max_step'], normalize='index')
pivot

# ì‹œê°í™”
pivot.plot(kind='bar', stacked=True, figsize=(10, 5), colormap='viridis')
plt.title('ì±„ìš©ê³µê³  ì„¸ê·¸ë¨¼íŠ¸ë³„ ìµœì¢… ë„ë‹¬ ë‹¨ê³„ ë¹„ìœ¨')
plt.xlabel('step4 ë¡œê·¸ ìˆ˜ ê¸°ì¤€ ì„¸ê·¸ë¨¼íŠ¸')
plt.ylabel('ë‹¨ê³„ë³„ ë„ë‹¬ ë¹„ìœ¨')
plt.legend(title='ìµœì¢… ë„ë‹¬ ë‹¨ê³„', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

"""```python
ğŸ’¡ ì„¸ê·¸ë¨¼íŠ¸ê°€ ë†’ì•„ì§ˆìˆ˜ë¡ ì´íƒˆë¥ ì´ ë‚®ê³ , ìµœì¢… ë‹¨ê³„ ë„ë‹¬ë¥ ì´ ë†’ë‹¤
ğŸ’¡ ì±„ìš©ê³µê³ ì— ëŒ€í•œ í´ë¦­ì´ ë§ì€ ìœ ì €ì¼ìˆ˜ë¡ ìµœì¢… ë‹¨ê³„ì— ë„ë‹¬í•˜ëŠ” ë¹„ìœ¨ì´ ë†’ë‹¤
âœ… ì±„ìš©ê³µê³ ì— ëŒ€í•œ í´ë¦­ ìˆ˜ëŠ” ë§¤ìš° ê°•ë ¥í•œ ì˜ˆì¸¡ ë³€ìˆ˜
ğŸ¤” ë‹¹ì—°í•´ë³´ì´ê¸´ í•˜ì§€ë§Œ, ê²€ì¦í–ˆë‹¤ëŠ” ê²ƒì— ì˜ì˜!
```

### ê°€ì„¤3) ê´€ë ¨ ê³µê³  ë¶ˆëŸ¬ì˜¤ê¸°ë¥¼ í´ë¦­í•œ ìœ ì €ì˜ ê²½ìš°, ì´íƒˆë¥ ì´ ë‚®ì„ ê²ƒì´ë‹¤
"""

# í•´ë‹¹ URL ë¡œê·¸ë§Œ í•„í„°ë§
otherjobs_condition = step4['URL'].str.contains('jobs/id/other_jobs')
step4_otherjobs = step4[otherjobs_condition]
step4_otherjobs

# ë¡œê·¸ ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í™”
step4_otherjobs_segment = step4_otherjobs.groupby('user_uuid')['step'].count().reset_index()
step4_otherjobs_segment.columns = ['user_uuid', 'step4_count']
step4_otherjobs_segment.describe()

# step4 ë¡œê·¸ ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì„¸ê·¸ë¨¼íŠ¸
step4_otherjobs_segment['segment'] = pd.qcut(step4_otherjobs_segment['step4_count'], q=3, labels=['low', 'mid', 'high'])
step4_otherjobs_segment.head(2)

# ìµœê³ ë‹¨ê³„ ë°ì´í„°ì™€ í•©ì¹˜ê¸°
merged = pd.merge(step4_otherjobs_segment, user_max_step, on='user_uuid', how='inner')
merged['segment'].value_counts()

# ì„¸ê·¸ë¨¼íŠ¸ë³„ ìµœì¢… ë‹¨ê³„ ë„ë‹¬ ë¹„ìœ¨ ë¹„êµ
pivot = pd.crosstab(merged['segment'], merged['max_step'], normalize='index')
pivot

# ì‹œê°í™”
pivot.plot(kind='bar', stacked=True, figsize=(10, 5), colormap='viridis')
plt.title('ìœ ì‚¬ê³µê³  í´ë¦­ ì„¸ê·¸ë¨¼íŠ¸ë³„ ìµœì¢… ë„ë‹¬ ë‹¨ê³„ ë¹„ìœ¨')
plt.xlabel('Step4 ë¡œê·¸ ìˆ˜ ê¸°ì¤€ ì„¸ê·¸ë¨¼íŠ¸')
plt.ylabel('ë‹¨ê³„ë³„ ë„ë‹¬ ë¹„ìœ¨')
plt.legend(title='ìµœì¢… ë„ë‹¬ ë‹¨ê³„', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

"""# 7. ìœ ì € ì—¬ì • ê¸°ë°˜ íŒ¨í„´ ë¶„ì„

## ìœ ì €ë³„ URL ì‹œí€€ìŠ¤ ì •ë¦¬
"""

log['timestamp'] = pd.to_datetime(log['timestamp'].str.replace(" UTC", "", regex=False), errors='coerce')

# 1) ìœ ì €ë³„ URL íë¦„ ì •ë¦¬
user_flow = log.sort_values(by=['user_uuid', 'timestamp'])
# 2) ìœ ì €ë³„ URL ì‹œí€€ìŠ¤ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¤ê¸°
user_url_step_path = user_flow.groupby('user_uuid').apply(lambda x: list(zip(x['step'], x['URL'], x['timestamp']))).reset_index(name='url_path')
user_url_step_path

"""## 6ë‹¨ê³„ ë„ë‹¬ ìœ ì €"""

completed_users = user_url_step_path[user_url_step_path['url_path'].apply(lambda x:any(step == 'step6' for step, URL, timestamp in x))]
completed_users

"""### ëœë¤ ìƒ˜í”Œë§"""

# random samplingì„ í†µí•´ ìœ ì €ì˜ ì—¬ì • í™•ì¸
# .sample(1) : ë¬´ì‘ìœ„ë¡œ 1í–‰ ë½‘ê¸°
sample_user = completed_users.sample(1).iloc[0]
sample_user

for step, url, timestamp in sample_user['url_path']:
     print(f"{timestamp} | {step}: {url}")

"""### ë¡œê·¸ ìˆ˜ ê¸°ì¤€ 25%, 50%, 75% user"""

# ê° ìœ ì €ì˜ ë¡œê·¸ ìˆ˜ ê³„ì‚°
completed_users['log_count'] = completed_users['url_path'].apply(len)

# ë¡œê·¸ ìˆ˜ ê¸°ì¤€ í¼ì„¼íƒ€ì¼ ìœ ì € ì„ íƒ
# .valueë¥¼ ë¶™ì´ë©´ Series í˜•ì‹ì„ Numpy ë°°ì—´ë¡œ ë³€ê²½
percentiles = [0.25, 0.5, 0.75]
quantile_values = completed_users['log_count'].quantile(percentiles).values

# ê° í¼ì„¼íƒ€ì¼ì— í•´ë‹¹í•˜ëŠ” log_count ê°’ê³¼ ê°€ì¥ ê°€ê¹Œìš´ ìœ ì € ì„ íƒ
selected_users = []
for value in quantile_values:
    # ì ˆëŒ€ê°’ ì°¨ì´ê°€ ê°€ì¥ ì ì€ ìœ ì € 1ëª… ì„ íƒ
    # .abs() : ì ˆëŒ€ê°’ìœ¼ë¡œ ê±°ë¦¬ë¥¼ ê³„ì‚°
    # .argsort() : ì ˆëŒ€ê°’ ê¸°ì¤€ìœ¼ë¡œ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬í•œ ì¸ë±ìŠ¤ ìˆœì„œë¥¼ ë°˜í™˜
    # [:1] : ê·¸ì¤‘ ê°€ì¥ ê°€ê¹Œìš´ ìœ ì € 1ëª…ë§Œ ì„ íƒ
    closest_user = completed_users.iloc[(completed_users['log_count']-value).abs().argsort()[:1]]
    selected_users.append(closest_user)

selected_users[1]

# ê²°ê³¼ì •ë¦¬ ë° ì €ì¥
selected_df = pd.concat(selected_users).drop_duplicates(subset='user_uuid')
selected_user_flows = {}

# .iterrows() : DFë¥¼ í•œ ì¤„ì”© ëŒë©´ì„œ rowë¡œ ê°€ì ¸ì˜¤ëŠ” ë°˜ë³µë¬¸
# _ëŠ” ì¸ë±ìŠ¤ì¸ë° ì‚¬ìš©í•˜ì§€ ì•Šì•„ì„œ ë¬´ì‹œí•œ ê²ƒ
for _, row in selected_df.iterrows():
    user_id = row['user_uuid']
    url_path = row['url_path']
    selected_user_flows[user_id] = url_path
    print(f"\n=== {user_id} ({len(url_path)} logs) ===")
    for step, url, timestamp in url_path:
        print(f"{timestamp} | {step}: {url}")

"""```python
ë¡œê·¸ ìˆ˜ 25% ìˆ˜ì¤€ì˜ ìœ ì € í–‰ë™ íŒ¨í„´
ğŸ§¾ ìš”ì•½ (Summary)
- ì´ ë¡œê·¸ ìˆ˜ : 240ê°œ
- ì´ìš© ê¸°ê°„ : 8ì›” 1ì¼ ~ 9ì›” 27ì¼

ğŸ” í¼ë„ íë¦„ ë¶„ì„
- step3ì—ì„œ company_id/jobì— ëŒ€í•œ ë¡œê·¸ê°€ ë§ì€ í¸
- íŠ¹ì • íšŒì‚¬, ì§ë¬´, ì‚¬ëŒì— ëŒ€í•œ íƒìƒ‰ì´ ì¦ì€ ê²ƒìœ¼ë¡œ ë³´ì•„ í¬ë§í•˜ëŠ” ê³µê³ ê°€ ë‚˜ì˜¬ ë•Œê¹Œì§€ ì ê·¹ íƒìƒ‰í•˜ëŠ” ê²ƒìœ¼ë¡œ ë³´ì„

ğŸ—“ï¸ ë‚ ì§œë³„ ë¡œê·¸
- 8ì›” 1ì¼, ì•½ 23ë¶„ ì ‘ì† : ìµœì´ˆ ì ‘ì† ë° íšŒì›ê°€ì… í›„, ì§ë¬´ ê²€ìƒ‰, íšŒì‚¬ ê²€ìƒ‰, íŠ¹ì • ì¡°ê±´(ì§€ì—­, ì§ë¬´ ì´ë¦„ ë“±)ì„ ë„£ëŠ” ê²€ìƒ‰ ì§„í–‰í–ˆê³  ì±„ìš© ê³µê³ ë¥¼ í´ë¦­í•œ í›„ ìœ ì‚¬ê³µê³ ê¹Œì§€ í™•ì¸
- 8ì›” 24ì¼, ì•½ 3ë¶„ ì ‘ì† : í¬íŠ¸í´ë¦¬ì˜¤ ì‘ì„±, ì§ë¬´ íƒìƒ‰, ê³µê³  í™•ì¸, ìœ ì‚¬ê³µê³  í™•ì¸ ì§„í–‰
- 8ì›” 25ì¼, 1ë¶„ ì ‘ì† : íŠ¹ì • íšŒì‚¬ì˜ ì§ë¬´, ì±„ìš© ê³µê³  í™•ì¸
- 9ì›” 5ì¼, ì•½ 16ë¶„ ì ‘ì† : í¬íŠ¸í´ë¦¬ì˜¤ ì‘ì„±, ì‚¬ëŒ ê²€ìƒ‰, ì§ë¬´ ê²€ìƒ‰, ì±„ìš©ê³µê³  í™•ì¸, ìœ ì‚¬ê³µê³  í™•ì¸, ë¶ë§ˆí¬ ì§„í–‰ >
- 9ì›” 13ì¼, ì•½ 15ë¶„ ì ‘ì† : ì§€ì—­ ì¡°ê±´ ê±¸ê³  ì§ë¬´ íƒìƒ‰, ì±„ìš©ê³µê³  í™•ì¸, ì§€ì›ì„œ ì‘ì„± 1ë‹¨ê³„ ì§„ì… í›„ ë‹¤ì‹œ ê°œì¸ í¬íŠ¸í´ë¦¬ì˜¤ë¡œ ë³µê·€, íŠ¹ì • ìƒí’ˆ ë° íšŒì‚¬ ê²€ìƒ‰, í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ì •
											  ì§€ì›ì„œ ë‹¨ê³„ë³„ ì‘ì„±, ì§€ì› ì™„ë£Œ
- 9ì›” 14ì¼, ì•½ 30ë¶„ ì ‘ì† : ê²€ìƒ‰ ë° ì±„ìš©ê³µê³  í™•ì¸
- 9ì›” 15ì¼ : ì§§ì€ ì ‘ì†ì„ í†µí•´ ìì‹ ì˜ ì§€ì›ì´ë ¥ í™•ì¸
- 9ì›” 27ì¼ : ì§§ê²Œ ì ‘ì†í•˜ì—¬ ì§€ì›ì„œ ì‘ì„±ë‹¨ê³„ ì‹œì‘í•¨ (ì‚¬ì „ì— ì €ì¥í•´ë‘” ì§€ì›ì„œì¼ì§€ë„)
```

```python
ë¡œê·¸ ìˆ˜ 50% ìˆ˜ì¤€ì˜ ìœ ì € í–‰ë™ íŒ¨í„´
ğŸ§¾ ìš”ì•½ (Summary)
- ì´ ë¡œê·¸ ìˆ˜ : 419ê°œ
- ì´ìš© ê¸°ê°„ : 6ì›” 7ì¼ ~ 6ì›” 25ì¼

ğŸ” í¼ë„ íë¦„ ë¶„ì„
- step1 íšŒì›ê°€ì… ë‹¨ê³„ì—ì„œ ê°œì¸ í”„ë¡œí•„ ê¼¼ê¼¼í•˜ê²Œ ì‘ì„±í•˜ëŠ” ìœ ì €ë¡œ ë³´ì„
- step4ì—ì„œ ì±„ìš©ê³µê³ ë¥¼ í™•ì¸í•œ í›„, ì§€ì›ì„œ ì‘ì„± ë° ì™„ë£Œê¹Œì§€ 3ë¶„, 8ë¶„ ë“± ì§§ê²Œ ì†Œìš”
- ì´ˆê¸° ì ‘ì†ì—ì„œëŠ” í¬íŠ¸í´ë¦¬ì˜¤ ë‹¨ê³„ì—ì„œì˜ ì ‘ì†ì´ ë§ì•˜ìœ¼ë‚˜ í›„ë°˜ë¶€ì—ëŠ” ê³§ë°”ë¡œ ì±„ìš©ê³µê³  í™•ì¸ ë° ì§€ì›ì„œ ì‘ì„± ë° ì™„ë£Œë¡œ ì´ì–´ì§

ğŸ—“ï¸ ë‚ ì§œë³„ ë¡œê·¸
- 6ì›” 7ì¼, ì•½ 14ë¶„ ì ‘ì† : íšŒì›ê°€ì… ì™„ë£Œ í›„ ê°œì¸ í¬íŠ¸í´ë¦¬ì˜¤ ë³´ì™„ ì§„í–‰
- 6ì›” 9ì¼ & 6ì›” 10ì¼ ì•½ 1ë¶„ ì ‘ì† : ì ‘ì† í›„ ê°œì¸ í¬íŠ¸í´ë¦¬ì˜¤ í™•ì¸
- 6ì›” 11ì¼, ì•½ 17ë¶„ ì ‘ì† : í¬íŠ¸í´ë¦¬ì˜¤ ë³´ì™„
- 6ì›” 12ì¼, ì•½ 1ì‹œê°„ ì ‘ì† : í¬íŠ¸í´ë¦¬ì˜¤ ë³´ì™„ì´ê±°ë‚˜ íŠ¹ì • íšŒì‚¬ì˜ êµ¬ì„±ì› í™•ì¸, ê°€ì…ìì— ëŒ€í•œ íƒìƒ‰ì„ ë§ì´ í•œ ê²ƒì²˜ëŸ¼ ë³´ì„
- 6ì›” 16ì¼, ì•½ 30ë¶„ ì ‘ì† : í¬íŠ¸í´ë¦¬ì˜¤ ë³´ì™„ì´ê±°ë‚˜ íŠ¹ì • ì¸ë¬¼ë“¤ íƒìƒ‰, ì§ë¬´ ê²€ìƒ‰, ì±„ìš©ê³µê³  í™•ì¸, ì‚¬ëŒ ê²€ìƒ‰, ì±„ìš©ê³µê³  í™•ì¸, íšŒì‚¬ ê²€ìƒ‰, ì±„ìš©ê³µê³  í™•ì¸ ì§„í–‰, ì§€ì›ì„œ ì‘ì„± ë° ì™„ë£Œ
												ì§€ì›ì™„ë£Œ í›„ ë‹¤ë¥¸ ê³µê³  í™•ì¸ ë° ì§€ì›ì„œ ì‘ì„± ë° ì™„ë£Œ, ì§€ì›ë‚´ì—­ 1ê°œ ì‚­ì œ, ì±„ìš©ê³µê³  ì¶”ê°€ í´ë¦­
- 6ì›” 25ì¼ : ì§ë¬´ ë° íšŒì‚¬ ê²€ìƒ‰, ì±„ìš©ê³µê³  í™•ì¸, ìœ ì‚¬ê³µê³  í™•ì¸, ì§€ì›ì„œ ì‘ì„± (ì™„ë£Œí•˜ì§€ ì•ŠìŒ), ìœ ì‚¬ê³µê³  í™•ì¸, ì§€ì›ì„œ ì‘ì„± ë° ì™„ë£Œ, ì¶”ê°€ ê³µê³  í™•ì¸, ì§€ì›ì„œ ì‘ì„± ë° ì™„ë£Œ

```

```python
ë¡œê·¸ ìˆ˜ 75% ìˆ˜ì¤€ì˜ ìœ ì € í–‰ë™ íŒ¨í„´
ğŸ§¾ ìš”ì•½ (Summary)
- ì´ ë¡œê·¸ ìˆ˜ : 748ê°œ
- ì´ìš© ê¸°ê°„ : 6ì›” 15ì¼ ~ 9ì›” 29ì¼

ğŸ” í¼ë„ íë¦„ ë¶„ì„
- í•˜ë£¨ì—ë„ ì—¬ëŸ¬ì°¨ë¡€ ì ‘ì†í•˜ëŠ” ìœ ì €
- ì¥ì‹œê°„ ì ‘ì† ìœ ì €
- ì±„ìš©ê³µê³  í™•ì¸ì— ëŒ€í•œ ë¡œê·¸ êµ‰ì¥íˆ ë§ê³ , ì§€ì›ì„œ ì‘ì„±ì„ ì¥ì‹œê°„&ì¥ê¸°ê°„ ì§„í–‰

ğŸ—“ï¸ ë‚ ì§œë³„ ë¡œê·¸
- 6ì›” 15ì¼, 10ì‹œê°„ ì ‘ì† : íšŒì›ê°€ì… í›„ í¬íŠ¸í´ë¦¬ì˜¤ ì‘ì„±, ì§ë¬´ ê²€ìƒ‰ ë° ì±„ìš©ê³µê³ , ìœ ì‚¬ê³µê³  í™•ì¸, ì§€ì›ì„œ ì‘ì„± ì‹œì‘ > ë‹¤ì‹œ í¬íŠ¸í´ë¦¬ì˜¤ ì‘ì„±ìœ¼ë¡œ ëŒì•„ì˜¨ í›„ ì§ë¬´ ë°
											ìƒí’ˆ êµ¬ì²´ì  ê²€ìƒ‰ ë°˜ë³µ > ì§€ì›ì™„ë£Œ > ì¶”ê°€ê²€ìƒ‰ ë° íƒìƒ‰, ì§€ì›ì„œ ì‘ì„± > ì§€ì›ì™„ë£Œ ë¥¼ ë°˜ë³µ
- 6ì›” 16ì¼, 1ì‹œê°„ 30ë¶„ ì ‘ì† í›„ 1íšŒ ì¶”ê°€ ì ‘ì† : ì§€ì›ì„œ ì‘ì„± > ì±„ìš©ê³µê³  í™•ì¸, ìœ ì‚¬ê³µê³  í™•ì¸ > ì§€ì›ì„œ ì‘ì„±
- 6ì›” 17ì¼, 4ì‹œê°„ ì ‘ì† : ê³§ ë°”ë¡œ ìì‹ ì˜ ì§€ì›ì„œ ì„¸ì…˜ìœ¼ë¡œ ì ‘ì† > ì§€ì›ì„œ ì‘ì„± > ì±„ìš©ê³µê³  í™•ì¸ > ë¶ë§ˆí¬ í™•ì¸ > ì§€ì›ì„œ ì‘ì„±
- 6ì›” 19ì¼, 5ë¶„ ì ‘ì†, ì´ 3íšŒ ì ‘ì† : ê³§ ë°”ë¡œ ìì‹ ì˜ ì§€ì›ì„œ ì„¸ì…˜ìœ¼ë¡œ ì ‘ì† > ì§€ì›ì„œ ì‘ì„± > ì±„ìš©ê³µê³  í™•ì¸ > ìœ ì‚¬ê³µê³  í™•ì¸
- 6ì›” 26ì¼, 10ë¶„ ì ‘ì†, ì´ 2íšŒ ì ‘ì† : íšŒì‚¬ íƒìƒ‰, ì§€ì›ì„œ ì‘ì„± > íšŒì‚¬ ë¶ë§ˆí¬ > íšŒì‚¬ í˜ì´ì§€ ë³´ê¸°
- 6ì›” 28ì¼, 5ë¶„ ì ‘ì† : í¬íŠ¸í´ë¦¬ì˜¤ í™•ì¸ ë° ë³´ì™„, ì‚¬ëŒ ê²€ìƒ‰
- 7ì›” 2ì¼, ì—¬ëŸ¬ì°¨ë¡€ ì ‘ì† : ì±„ìš©ê³µê³  í™•ì¸ > í¬íŠ¸í´ë¦¬ì˜¤ ë³´ì™„ > ì§€ì›ì„œ ì‘ì„± > íšŒì‚¬ ë° ì§ë¬´, ê³µê³  ê²€ìƒ‰ ë° í™•ì¸ > ì§€ì›ì„œ ì‘ì„±
- 7ì›” 3ì¼, 5ë¶„ ì ‘ì† : ê²€ìƒ‰
- 7ì›” 5ì¼ : ì§€ì›ì„œ ì‘ì„±...step3ê¹Œì§€ ê°„ê±¸ë³´ë©´ ì™„ë£Œì¼ì§€ë„
- 7ì›” 9ì¼, 7ì›” 27ì¼, 8ì›” 4ì¼, 8ì›” 7ì¼, 9ì›” 2ì¼ : ì ì‹œ ì ‘ì†í•˜ì—¬ íŠ¹ì • íšŒì‚¬ í™•ì¸ ë° í¬íŠ¸í´ë¦¬ì˜¤ í™•ì¸
- 9ì›” 5ì¼ : ê³µê³  í™•ì¸, ì§€ì›ì„œ ì‘ì„±, ì§€ì›ì™„ë£Œ, í¬íŠ¸í´ë¦¬ì˜¤ ë³´ì™„
```
"""

!pip install plotly pandas
import plotly.express as px

# ìœ ì €ë³„ ë¡œê·¸ë¥¼ ëª¨ì•„ì¤„ ë¦¬ìŠ¤íŠ¸
records = []

# selected_user_flows: {user_uuid: [(step, url, timestamp), ...]}
for user_id, url_path in selected_user_flows.items():
    for step, url, timestamp in url_path:
        records.append({
            'user_id': user_id,
            'step': step,
            'url': url,
            'timestamp': pd.to_datetime(timestamp)
        })

# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
df_timeline = pd.DataFrame(records)

# step ì •ë ¬ ìˆœì„œ ëª…ì‹œ (ì•ˆ í•˜ë©´ ì•ŒíŒŒë²³ ìˆœ)
step_order = ['step1', 'step2', 'step3', 'step4', 'step5', 'step6']
df_timeline['step'] = pd.Categorical(df_timeline['step'], categories=step_order, ordered=True)

# ì‹œê°í™”
fig = px.line(df_timeline,
              x="timestamp",
              y="step",
              color="user_id",
              markers=True,
              title="ìœ ì €ë³„ í¼ë„ ë‹¨ê³„ íƒ€ì„ë¼ì¸",
              labels={"step": "í¼ë„ ë‹¨ê³„", "timestamp": "ì‹œê°„", "user_id": "ìœ ì €"},
              hover_data=["url"])

fig.update_layout(yaxis=dict(categoryorder='array', categoryarray=step_order))

fig.show()

"""## 5ë‹¨ê³„ ì´íƒˆ ìœ ì €"""

import re

def extract_max_step(path):
    steps = [int(re.search(r'\d+', step).group()) for step, _, _ in path]
    return max(steps)

dropoff_users = user_url_step_path[user_url_step_path['url_path'].apply(lambda path: extract_max_step(path) == 5)]

dropoff_users.shape

sample_dropoff_user = dropoff_users.copy()

# ê° ìœ ì €ì˜ ë¡œê·¸ ìˆ˜ ê³„ì‚°
sample_dropoff_user['log_count'] = sample_dropoff_user['url_path'].apply(len)

# í¼ì„¼íƒ€ì¼ ê³„ì‚°
percentiles = [0.25, 0.5, 0.75]
quantile_values = sample_dropoff_user['log_count'].quantile(percentiles).values

# ê° í¼ì„¼íƒ€ì¼ì— í•´ë‹¹í•˜ëŠ” log_count ê°’ê³¼ ê°€ì¥ ê°€ê¹Œìš´ ìœ ì € ì„ íƒ
selected_users = []
for value in quantile_values:
    # ì ˆëŒ€ê°’ ì°¨ì´ê°€ ê°€ì¥ ì ì€ ìœ ì € 1ëª… ì„ íƒ
    # .abs() : ì ˆëŒ€ê°’ìœ¼ë¡œ ê±°ë¦¬ë¥¼ ê³„ì‚°
    # .argsort() : ì ˆëŒ€ê°’ ê¸°ì¤€ìœ¼ë¡œ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬í•œ ì¸ë±ìŠ¤ ìˆœì„œë¥¼ ë°˜í™˜
    # [:1] : ê·¸ì¤‘ ê°€ì¥ ê°€ê¹Œìš´ ìœ ì € 1ëª…ë§Œ ì„ íƒ
    closest_user = sample_dropoff_user.iloc[(sample_dropoff_user['log_count']-value).abs().argsort()[:1]]
    selected_users.append(closest_user)

# ê²°ê³¼ì •ë¦¬ ë° ì €ì¥
selected_df = pd.concat(selected_users).drop_duplicates(subset='user_uuid')
selected_user_flows = {}

# .iterrows() : DFë¥¼ í•œ ì¤„ì”© ëŒë©´ì„œ rowë¡œ ê°€ì ¸ì˜¤ëŠ” ë°˜ë³µë¬¸
# _ëŠ” ì¸ë±ìŠ¤ì¸ë° ì‚¬ìš©í•˜ì§€ ì•Šì•„ì„œ ë¬´ì‹œí•œ ê²ƒ
for _, row in selected_df.iterrows():
    user_id = row['user_uuid']
    url_path = row['url_path']
    selected_user_flows[user_id] = url_path
    print(f"\n=== {user_id} ({len(url_path)} logs) ===")
    for step, url, timestamp in url_path:
        print(f"{timestamp} | {step}: {url}")

# ìœ ì €ë³„ ë¡œê·¸ë¥¼ ëª¨ì•„ì¤„ ë¦¬ìŠ¤íŠ¸
records = []

# selected_user_flows: {user_uuid: [(step, url, timestamp), ...]}
for user_id, url_path in selected_user_flows.items():
    for step, url, timestamp in url_path:
        records.append({
            'user_id': user_id,
            'step': step,
            'url': url,
            'timestamp': pd.to_datetime(timestamp)
        })

# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
df_timeline = pd.DataFrame(records)

# step ì •ë ¬ ìˆœì„œ ëª…ì‹œ (ì•ˆ í•˜ë©´ ì•ŒíŒŒë²³ ìˆœ)
step_order = ['step1', 'step2', 'step3', 'step4', 'step5', 'step6']
df_timeline['step'] = pd.Categorical(df_timeline['step'], categories=step_order, ordered=True)

# ì‹œê°í™”
fig = px.line(df_timeline,
              x="timestamp",
              y="step",
              color="user_id",
              markers=True,
              title="ìœ ì €ë³„ í¼ë„ ë‹¨ê³„ íƒ€ì„ë¼ì¸",
              labels={"step": "í¼ë„ ë‹¨ê³„", "timestamp": "ì‹œê°„", "user_id": "ìœ ì €"},
              hover_data=["url"])

fig.update_layout(yaxis=dict(categoryorder='array', categoryarray=step_order))

fig.show()

"""## 4ë‹¨ê³„ ì´íƒˆ ìœ ì €

### ëœë¤ ìƒ˜í”Œë§
"""

def extract_max_step(path):
    steps = [int(re.search(r'\d+', step).group()) for step, _, _ in path]
    return max(steps)

dropoff_users = user_url_step_path[user_url_step_path['url_path'].apply(lambda path: extract_max_step(path) == 4)]

dropoff_users.shape

sample_dropoff_user = dropoff_users.sample(1).iloc[0]

sample_dropoff_user

for step, url, timestamp in sample_dropoff_user['url_path']:
    print(f"{timestamp} | {step}: {url}")

"""### ë¡œê·¸ ìˆ˜ ê¸°ì¤€ 25%, 50%, 75% user"""

sample_dropoff_user = dropoff_users.copy()

# ê° ìœ ì €ì˜ ë¡œê·¸ ìˆ˜ ê³„ì‚°
sample_dropoff_user['log_count'] = sample_dropoff_user['url_path'].apply(len)

# í¼ì„¼íƒ€ì¼ ê³„ì‚°
percentiles = [0.25, 0.5, 0.75]
quantile_values = sample_dropoff_user['log_count'].quantile(percentiles).values

# ê° í¼ì„¼íƒ€ì¼ì— í•´ë‹¹í•˜ëŠ” log_count ê°’ê³¼ ê°€ì¥ ê°€ê¹Œìš´ ìœ ì € ì„ íƒ
selected_users = []
for value in quantile_values:
    # ì ˆëŒ€ê°’ ì°¨ì´ê°€ ê°€ì¥ ì ì€ ìœ ì € 1ëª… ì„ íƒ
    # .abs() : ì ˆëŒ€ê°’ìœ¼ë¡œ ê±°ë¦¬ë¥¼ ê³„ì‚°
    # .argsort() : ì ˆëŒ€ê°’ ê¸°ì¤€ìœ¼ë¡œ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬í•œ ì¸ë±ìŠ¤ ìˆœì„œë¥¼ ë°˜í™˜
    # [:1] : ê·¸ì¤‘ ê°€ì¥ ê°€ê¹Œìš´ ìœ ì € 1ëª…ë§Œ ì„ íƒ
    closest_user = sample_dropoff_user.iloc[(sample_dropoff_user['log_count']-value).abs().argsort()[:1]]
    selected_users.append(closest_user)

# ê²°ê³¼ì •ë¦¬ ë° ì €ì¥
selected_df = pd.concat(selected_users).drop_duplicates(subset='user_uuid')
selected_user_flows = {}

# .iterrows() : DFë¥¼ í•œ ì¤„ì”© ëŒë©´ì„œ rowë¡œ ê°€ì ¸ì˜¤ëŠ” ë°˜ë³µë¬¸
# _ëŠ” ì¸ë±ìŠ¤ì¸ë° ì‚¬ìš©í•˜ì§€ ì•Šì•„ì„œ ë¬´ì‹œí•œ ê²ƒ
for _, row in selected_df.iterrows():
    user_id = row['user_uuid']
    url_path = row['url_path']
    selected_user_flows[user_id] = url_path
    print(f"\n=== {user_id} ({len(url_path)} logs) ===")
    for step, url, timestamp in url_path:
        print(f"{timestamp} | {step}: {url}")

# ìœ ì €ë³„ ë¡œê·¸ë¥¼ ëª¨ì•„ì¤„ ë¦¬ìŠ¤íŠ¸
records = []

# selected_user_flows: {user_uuid: [(step, url, timestamp), ...]}
for user_id, url_path in selected_user_flows.items():
    for step, url, timestamp in url_path:
        records.append({
            'user_id': user_id,
            'step': step,
            'url': url,
            'timestamp': pd.to_datetime(timestamp)
        })

# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
df_timeline = pd.DataFrame(records)

# step ì •ë ¬ ìˆœì„œ ëª…ì‹œ (ì•ˆ í•˜ë©´ ì•ŒíŒŒë²³ ìˆœ)
step_order = ['step1', 'step2', 'step3', 'step4', 'step5', 'step6']
df_timeline['step'] = pd.Categorical(df_timeline['step'], categories=step_order, ordered=True)

# ì‹œê°í™”
fig = px.line(df_timeline,
              x="timestamp",
              y="step",
              color="user_id",
              markers=True,
              title="ìœ ì €ë³„ í¼ë„ ë‹¨ê³„ íƒ€ì„ë¼ì¸",
              labels={"step": "í¼ë„ ë‹¨ê³„", "timestamp": "ì‹œê°„", "user_id": "ìœ ì €"},
              hover_data=["url"])

fig.update_layout(yaxis=dict(categoryorder='array', categoryarray=step_order))

fig.show()

"""## 3ë‹¨ê³„ ì´íƒˆ ìœ ì €

### ëœë¤ ìƒ˜í”Œë§
"""

def extract_max_step(path):
    steps = [int(re.search(r'\d+', step).group()) for step, _, _ in path]
    return max(steps)

dropoff_users = user_url_step_path[user_url_step_path['url_path'].apply(lambda path: extract_max_step(path) == 3)]

dropoff_users.shape

sample_dropoff_user = dropoff_users.sample(1).iloc[0]
sample_dropoff_user

for step, url, timestamp in sample_dropoff_user['url_path']:
    print(f"{timestamp} | {step}: {url}")

"""### ë¡œê·¸ ìˆ˜ ê¸°ì¤€ 25%, 50%, 75% user"""

sample_dropoff_user = dropoff_users.copy()

# ê° ìœ ì €ì˜ ë¡œê·¸ ìˆ˜ ê³„ì‚°
sample_dropoff_user['log_count'] = sample_dropoff_user['url_path'].apply(len)

# í¼ì„¼íƒ€ì¼ ê³„ì‚°
percentiles = [0.25, 0.5, 0.75]
quantile_values = sample_dropoff_user['log_count'].quantile(percentiles).values

# ê° í¼ì„¼íƒ€ì¼ì— í•´ë‹¹í•˜ëŠ” log_count ê°’ê³¼ ê°€ì¥ ê°€ê¹Œìš´ ìœ ì € ì„ íƒ
selected_users = []
for value in quantile_values:
    # ì ˆëŒ€ê°’ ì°¨ì´ê°€ ê°€ì¥ ì ì€ ìœ ì € 1ëª… ì„ íƒ
    # .abs() : ì ˆëŒ€ê°’ìœ¼ë¡œ ê±°ë¦¬ë¥¼ ê³„ì‚°
    # .argsort() : ì ˆëŒ€ê°’ ê¸°ì¤€ìœ¼ë¡œ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬í•œ ì¸ë±ìŠ¤ ìˆœì„œë¥¼ ë°˜í™˜
    # [:1] : ê·¸ì¤‘ ê°€ì¥ ê°€ê¹Œìš´ ìœ ì € 1ëª…ë§Œ ì„ íƒ
    closest_user = sample_dropoff_user.iloc[(sample_dropoff_user['log_count']-value).abs().argsort()[:1]]
    selected_users.append(closest_user)

# ê²°ê³¼ì •ë¦¬ ë° ì €ì¥
selected_df = pd.concat(selected_users).drop_duplicates(subset='user_uuid')
selected_user_flows = {}

# .iterrows() : DFë¥¼ í•œ ì¤„ì”© ëŒë©´ì„œ rowë¡œ ê°€ì ¸ì˜¤ëŠ” ë°˜ë³µë¬¸
# _ëŠ” ì¸ë±ìŠ¤ì¸ë° ì‚¬ìš©í•˜ì§€ ì•Šì•„ì„œ ë¬´ì‹œí•œ ê²ƒ
for _, row in selected_df.iterrows():
    user_id = row['user_uuid']
    url_path = row['url_path']
    selected_user_flows[user_id] = url_path
    print(f"\n=== {user_id} ({len(url_path)} logs) ===")
    for step, url, timestamp in url_path:
        print(f"{timestamp} | {step}: {url}")

# ìœ ì €ë³„ ë¡œê·¸ë¥¼ ëª¨ì•„ì¤„ ë¦¬ìŠ¤íŠ¸
records = []

# selected_user_flows: {user_uuid: [(step, url, timestamp), ...]}
for user_id, url_path in selected_user_flows.items():
    for step, url, timestamp in url_path:
        records.append({
            'user_id': user_id,
            'step': step,
            'url': url,
            'timestamp': pd.to_datetime(timestamp)
        })

# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
df_timeline = pd.DataFrame(records)

# step ì •ë ¬ ìˆœì„œ ëª…ì‹œ (ì•ˆ í•˜ë©´ ì•ŒíŒŒë²³ ìˆœ)
step_order = ['step1', 'step2', 'step3', 'step4', 'step5', 'step6']
df_timeline['step'] = pd.Categorical(df_timeline['step'], categories=step_order, ordered=True)

# ì‹œê°í™”
fig = px.line(df_timeline,
              x="timestamp",
              y="step",
              color="user_id",
              markers=True,
              title="ìœ ì €ë³„ í¼ë„ ë‹¨ê³„ íƒ€ì„ë¼ì¸",
              labels={"step": "í¼ë„ ë‹¨ê³„", "timestamp": "ì‹œê°„", "user_id": "ìœ ì €"},
              hover_data=["url"])

fig.update_layout(yaxis=dict(categoryorder='array', categoryarray=step_order))

fig.show()

